{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-frequency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "generous-cigarette",
   "metadata": {},
   "source": [
    "F Beta Score\n",
    "\n",
    "Its a measure which helps us balance precision and recall.\n",
    "\n",
    "Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "\n",
    "As we know our goal is always to reduce  the FalsePositives and FalseNegatives. F-Beta provides a balance between FalsePositives and FalseNegatives.\n",
    "\n",
    "Formulae:\n",
    "Fbeta = ((1 + beta^2) * Precision * Recall) / (beta^2 * Precision + Recall)\n",
    "\n",
    "From formule we can clearly identify that beta is taken into account with Precision which deals with FalsePositive. Hence when we want to put more weight on FalsePositive(i.e Precision) than on FalseNegative we can use a smaller beta value (beta < 1 and when we want more weight to be given to FalseNegative (i.e Recall), we can use a greater value (beta > 1). If we want a balanced value between precision and call we can use beta value as 1.\n",
    "\n",
    "Rules and Examples:\n",
    "\n",
    "F0.5-Measure (beta=0.5):\n",
    "F0.5-measure puts more attention on minimizing false positives than minimizing false negatives. \n",
    "ex. In case of spam check, we want very low false positives because if regular mail is reported as spam, user might lose important information hence we can more focus on precision.\n",
    "\n",
    "\n",
    "F2-Measure (beta=2.0): Less weight on precision, more weight on recall.\n",
    "ex. In case of airport we don't want any dangerous items to be boarded into a flight. Hence we want to reduce falseNegatives putting more value on Recall.\n",
    "\n",
    "\n",
    "Compariosion of F 0.5, F1 & F2\n",
    "Suppose for below scenarios where we have perfect precision and 50% recall.\n",
    "Precision = 1.0\n",
    "Recall = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "If Beta = 1: \n",
    "F1-Measure = ((1 + 1^2) * Precision * Recall) / (1^2 * Precision + Recall)\n",
    "F1-Measure = (2 * 1.0 * 0.5) / ( 1.0 + 0.5 )\n",
    "F1-Measure = 1.0 / 1.5\n",
    "F1-Measure = 0.666\n",
    "\n",
    "\n",
    "If Beta = 0.5\n",
    "F0.5-Measure = ((1 + 0.5^2) * Precision * Recall) / (0.5^2 * Precision + Recall)\n",
    "F0.5-Measure = (1.25 * Precision * Recall) / (0.25 * Precision + Recall)\n",
    "F0.5-Measure = (1.25 * 1.0 * 0.5) / (0.25 * 1.0 + 0.5)\n",
    "F0.5-Measure = 0.625 /0.75\n",
    "F0.5-Measure = 0.833\n",
    "\n",
    "As in Beta < 1 we want to provide more weightage to the Precision, we can clearly see a higher precision score of 0.83 which is much more than the normal F1 score. We are not getting penalized for the low recall.\n",
    "\n",
    "\n",
    "If Beta = 2.0\n",
    "F2-Measure = ((1 + 2^2) * Precision * Recall) / (2^2 * Precision + Recall)\n",
    "F2-Measure = (5 * Precision * Recall) / (4 * Precision + Recall)\n",
    "F2-Measure = (5 * 1.0 * 0.5) / (4 * 1.0 + 0.5)\n",
    "F2-Measure = 2.5 /4.5\n",
    "F2-Measure = 0.555\n",
    "\n",
    "As in Beta > 1 we want to provide more weightage to the Recall, we can clearly see a lower score of 0.555 which is much less than the normal F1 score. We are getting penalized for the low recall value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-possible",
   "metadata": {},
   "source": [
    "Cohen Kappa\n",
    "\n",
    "When we compute accuracy we don't take into account the random chance which lead to the model predict correct values. As this random hits can be further taken into account to compute accuracy we can use kappa score to handle these scenarios. Cohen Kappa is particularly useful when the target class is unbalanced which leads to overall accuracy being biased.\n",
    "\n",
    "Inititally introduced to measure aggrement between observers of psychological behavior it's actually intended to measure the degree of agreement, or disagreement, between two people which are observing a same experiment. Cohens kappa has universal range from -1 to +1. Postive one indicates strong aggrement or a perfect model, negative corresponds to a strong disagreement while zero indicates chance-level aggrement.\n",
    "\n",
    "\n",
    "-> Cohen's Kappa for binary districution\n",
    "\n",
    "Customer with good rating represent 90% of the data and customer with bad rating represent 10% of the data. A classification model that predicts a rating of all customers as good would reach an accuracy of as high as 90%. Cohen's Kappa tries to correct this bias by taking into account the priori distribution.\n",
    "\n",
    "\n",
    "\n",
    "k = (Po - Pe) / (1 - Pe)\n",
    "Po -> Overall accuracy of the model i.e. is the proportion of observed agreement\n",
    "Pe -> Overall accuracy that can be reached with a random guess i.e. the Expected Accuracy, the level of Accuracy we expect to obtain by chance.\n",
    "1- Pe -> is the maximum value of this difference as give by a perfect model with accuracy of 100%\n",
    "\n",
    "\n",
    "To calucate overall accuracy for a random guess Pe, we make a strong assumption that the model predictions are not affected by the priori distribution of the target class. This assumption is often violated when working with unbalanced data since the classification model tends to predict the majority class in case of uncertinity.\n",
    "\n",
    "However be caeful when you compare cohen kappa values between models, because cohen's kappa tends to be higher when the target classes are balanced.\n",
    "\n",
    "Cohen's Kappa is not informative about expected prediction accuracy. The interpretation of cohen's Kappa alues in terms like \"moderate\" is neither easy not fixed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-architecture",
   "metadata": {},
   "source": [
    "Mattheus Correlation Coefficient (MCC)\n",
    "\n",
    "\n",
    "MCC is a tool for model evaluation. It measures the differences between actual values and predicted values and is equivalent to the chi-square statistic for a 2 x 2 contingency table.\n",
    "     \n",
    "MCC is generally regarded as a balanced measure which can be used in binary classification even if the classes are very different in size. The coefficient takes into account true negatives, true positives, false negatives and false positives. This reliable measure produces high scores only if the prediction returns good rates for all four of these categories.\n",
    "     \n",
    "     Like most correlation coefficients, MCC ranges between -1 and 1:\n",
    "    - 1 is the best agreement between actuals and predictions,\n",
    "    - zero is no agreement at all. In other words, the prediction is random with respect to actuals.\n",
    "\n",
    "MCC for binary distriution\n",
    "\n",
    "As MCC takes into account full confusion matrix below is the formulae for the same.\n",
    "\n",
    "MCC = TP * TN - FP * FN / ((TP + FP)(TP + FP)(TN + FN)(TN + FP))\n",
    "\n",
    "\n",
    "  Imagine we have a classifier that is trying to differenciate between cats and dogs by identifying them based on their images. Below is the confusion matrix:\n",
    "    \n",
    "    || Cat | Dog |  |\n",
    "    |cat| 109 | 1 | 110 |\n",
    "    |Dog| 9 | 1 | 10 |\n",
    "    || 118 | 2 | 120 |\n",
    "    \n",
    "    We can see we have predicted only 1 out of 10 dog correctly while 109 cats were correctly identified.\n",
    "    \n",
    "      Scenario 1: \n",
    "        cats are positive  \n",
    "        dogs are negative\n",
    "    \n",
    "    | Evaluation Matrix | Value | \n",
    "    | :- | -: |\n",
    "    | **Accuracy** | (109 + 1)/ 120 = 0.92 |\n",
    "    | **Precision** | 109/ (109+9) = 0.92 |\n",
    "    | **Recall** | 109/ (109+1) = 0.99  |\n",
    "    | **F1 Score** | 0.95  |\n",
    "    \n",
    "    Scenario 2: \n",
    "        cats are negative  \n",
    "        dogs are positive\n",
    " \n",
    "     | Evaluation Matrix | Value | \n",
    "    | :- | -: |\n",
    "    | **Accuracy** | (109 + 1)/ 120 = 0.92 |\n",
    "    | **Precision** | 1/ (1+1) = 0.50 |\n",
    "    | **Recall** | 1/ (9+1) = 0.10  |\n",
    "    | **F1 Score** | 0.16  |\n",
    "\n",
    "\n",
    "F1 score does not take into account TN at all which is the reason of this drop in percentage.\n",
    "    \n",
    "    Using MCC formule we get a value **MCC = 0.21**. MCC has a low value which suggests that even with a high positive class results it still gave us poor score because our negative class was not well predicted (1 out of 10 was predicted correctly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-simulation",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=GNpAWoG5skM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-moscow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-machine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-package",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "leading-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Predicted Class  Actual Class\n",
      "0                  0             0\n",
      "1                  0             0\n",
      "2                  1             0\n",
      "3                  0             0\n",
      "4                  0             0\n",
      "..               ...           ...\n",
      "155                3             3\n",
      "156                3             3\n",
      "157                3             3\n",
      "158                2             3\n",
      "159                0             3\n",
      "\n",
      "[160 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(\"dataset.xlsx\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "level-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "total_class = df[\"Predicted Class\"].unique().size\n",
    "print(total_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "miniature-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  8  4  4]\n",
      " [ 1 32  3  0]\n",
      " [ 3  2 29  6]\n",
      " [ 2  3  3 27]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros([total_class, total_class], dtype = int) \n",
    "\n",
    "for i in range(len(df)) : \n",
    "    np.add.at(confusion_matrix[df.iloc[i, 1]], df.iloc[i, 0], 1)\n",
    "\n",
    "print(confusion_matrix)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "natural-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 36 40 35]\n",
      "[39 45 39 37]\n"
     ]
    }
   ],
   "source": [
    "actual_cases = np.sum(confusion_matrix, axis = 1)\n",
    "print(actual_cases)\n",
    "\n",
    "predicted_cases = np.sum(confusion_matrix, axis = 0)\n",
    "print(predicted_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protecting-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33 32 29 27]\n",
      "[16  4 11  8]\n"
     ]
    }
   ],
   "source": [
    "fn_cases = np.zeros([total_class], dtype = int) \n",
    "tp_cases = np.zeros([total_class], dtype = int) \n",
    "\n",
    "for row in range(0, total_class):\n",
    "    sum = 0\n",
    "    for column in range(0, total_class):\n",
    "        if(row == column):\n",
    "            tp_cases[row] = confusion_matrix[row][column] \n",
    "            continue\n",
    "        sum = sum + confusion_matrix[row][column]    \n",
    "    fn_cases[row] = sum        \n",
    "\n",
    "print(tp_cases)    \n",
    "print(fn_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharp-indicator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  4 11  8]\n",
      "[ 95 120 109 117]\n"
     ]
    }
   ],
   "source": [
    "fp_cases = predicted_cases - tp_cases\n",
    "print(fn_cases)\n",
    "\n",
    "tn_cases = actual_cases.sum() - (actual_cases + fn_cases)\n",
    "print(tn_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "charming-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67346939 0.88888889 0.725      0.77142857]\n",
      "[0.94059406 0.90225564 0.91596639 0.92125984]\n"
     ]
    }
   ],
   "source": [
    "tnr = tn_cases / (fp_cases + tn_cases)\n",
    "tpr = tp_cases / (fn_cases + tp_cases)\n",
    "\n",
    "print(tpr)\n",
    "print(tnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vocational-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80703172 0.89557226 0.82048319 0.84634421]\n"
     ]
    }
   ],
   "source": [
    "class_accuracy = ( tpr + tnr ) / 2 \n",
    "\n",
    "print(class_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "herbal-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75625\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = tp_cases.sum() / actual_cases.sum()\n",
    "print(overall_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consolidated-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84615385 0.71111111 0.74358974 0.72972973]\n"
     ]
    }
   ],
   "source": [
    "precision = tp_cases / ( tp_cases + fp_cases )\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bottom-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7576461076461076\n"
     ]
    }
   ],
   "source": [
    "macro_precision = precision.sum() / precision.size\n",
    "print(macro_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "virtual-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75625\n"
     ]
    }
   ],
   "source": [
    "micro_precision = tp_cases.sum() / (tp_cases.sum() + fp_cases.sum())\n",
    "print(micro_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25913462 0.16       0.18589744 0.15962838]\n"
     ]
    }
   ],
   "source": [
    "weighted_average_precision = (actual_cases / actual_cases.sum()) * precision\n",
    "print(weighted_average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metropolitan-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67346939 0.88888889 0.725      0.77142857]\n"
     ]
    }
   ],
   "source": [
    "recall = tp_cases / ( tp_cases + fn_cases )\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quarterly-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20625 0.2     0.18125 0.16875]\n"
     ]
    }
   ],
   "source": [
    "weighted_average_recall = (actual_cases / actual_cases.sum()) * recall\n",
    "print(weighted_average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "italic-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80487805 0.74074074 0.73979592 0.73770492]\n"
     ]
    }
   ],
   "source": [
    "f05 = ((1 + 0.5 ** 2) * precision * recall) / ((0.5 ** 2 * precision) + recall)\n",
    "print(f05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nervous-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.79012346 0.73417722 0.75      ]\n"
     ]
    }
   ],
   "source": [
    "f1 = 2 / (1 / precision + 1 / recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "super-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70212766 0.84656085 0.72864322 0.76271186]\n"
     ]
    }
   ],
   "source": [
    "f2 = ((1 + 2 ** 2) * precision * recall) / ((2 ** 2 * precision) + recall)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mineral-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2296875  0.17777778 0.1835443  0.1640625 ]\n"
     ]
    }
   ],
   "source": [
    "weighted_average_f1 = (actual_cases / actual_cases.sum()) * f1\n",
    "print(weighted_average_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "historic-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05940594 0.09774436 0.08403361 0.07874016]\n",
      "[0.32653061 0.11111111 0.275      0.22857143]\n"
     ]
    }
   ],
   "source": [
    "fpr = fp_cases / ( tn_cases + fp_cases )\n",
    "fnr = fn_cases / ( fn_cases + tp_cases )\n",
    "\n",
    "print(fpr)\n",
    "print(fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "guided-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752368064952639\n"
     ]
    }
   ],
   "source": [
    "class_sum = (actual_cases * predicted_cases).sum()\n",
    "actual_cases.sum() * tp_cases.sum()\n",
    "\n",
    "kappa_value = ((actual_cases.sum() * tp_cases.sum()) - class_sum) / ((actual_cases.sum() ** 2) - class_sum) \n",
    "print(kappa_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "square-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>Class 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Cases</th>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Samples</th>\n",
       "      <td>39</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>109</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Class 0  Class 1  Class 3  Class 4\n",
       "Actual Cases        49       36       40       35\n",
       "Total Samples       39       45       39       37\n",
       "TP                  33       32       29       27\n",
       "FP                   6       13       10       10\n",
       "TN                  95      120      109      117\n",
       "FN                  16        4       11        8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_df = pd.DataFrame(np.array(\n",
    "                    [actual_cases, predicted_cases, tp_cases, fp_cases, tn_cases, fn_cases]),\n",
    "                columns=['Class 0', 'Class 1', 'Class 3', 'Class 4'],\n",
    "                index = ['Actual Cases', 'Total Samples', 'TP', 'FP' , 'TN', 'FN'])\n",
    "\n",
    "basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "nominated-penny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>Class 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.921260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type 1 Error</th>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>0.078740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type 2 Error</th>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.734177</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Class 0   Class 1   Class 3   Class 4\n",
       "TPR           0.673469  0.888889  0.725000  0.771429\n",
       "TNR           0.940594  0.902256  0.915966  0.921260\n",
       "Type 1 Error  0.059406  0.097744  0.084034  0.078740\n",
       "Type 2 Error  0.326531  0.111111  0.275000  0.228571\n",
       "Precision     0.846154  0.711111  0.743590  0.729730\n",
       "Recall        0.673469  0.888889  0.725000  0.771429\n",
       "F1            0.750000  0.790123  0.734177  0.750000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_df = pd.DataFrame(np.array(\n",
    "                    [ tpr, tnr, fpr, fnr, precision, recall, f1 ]),\n",
    "                columns=['Class 0', 'Class 1', 'Class 3', 'Class 4'],\n",
    "                index = ['TPR', 'TNR', 'Type 1 Error', 'Type 2 Error','Precision', 'Recall', 'F1'])\n",
    "rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-double",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-completion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "classical-islam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752368064952639\n",
      "0.6752368064952639\n",
      "[[33  8  4  4]\n",
      " [ 1 32  3  0]\n",
      " [ 3  2 29  6]\n",
      " [ 2  3  3 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.85      0.67      0.75        49\n",
      "     Class 1       0.71      0.89      0.79        36\n",
      "     Class 2       0.74      0.72      0.73        40\n",
      "     Class 3       0.73      0.77      0.75        35\n",
      "\n",
      "    accuracy                           0.76       160\n",
      "   macro avg       0.76      0.76      0.76       160\n",
      "weighted avg       0.76      0.76      0.76       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "#from sklearn.metrics import precision_score\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(cohen_kappa_score(df['Actual Class'], df['Predicted Class']))\n",
    "print(cohen_kappa_score(df['Predicted Class'], df['Actual Class']))\n",
    "\n",
    "auto_cf_matrix = confusion_matrix(df['Actual Class'], df['Predicted Class'])\n",
    "print(auto_cf_matrix)\n",
    "\n",
    "print(classification_report(df['Actual Class'], df['Predicted Class'], target_names=['Class 0' , 'Class 1', 'Class 2', 'Class 3']))\n",
    "#print(accuracy_score(df['Actual Class'], df['Predicted Class']))\n",
    "#print(precision_score(df['Actual Class'], df['Predicted Class'], average='macro'))\n",
    "#print(precision_score(df['Actual Class'], df['Predicted Class'], average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-leone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-proof",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-grave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-fossil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accessory-advertiser",
   "metadata": {},
   "source": [
    "class_accuracy = np.zeros([total_class], dtype = float) \n",
    "\n",
    "for each in range(0, total_class):\n",
    "    class_accuracy[each] = (tpr[each] + tnr[each]) / 2\n",
    "    \n",
    "print(class_accuracy)\n",
    "print(class_accuracy.sum()/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-charter",
   "metadata": {},
   "source": [
    "tn_cases = np.zeros([total_class], dtype = int) \n",
    "fn_cases = np.zeros([total_class], dtype = int) \n",
    "\n",
    "for each in range(0, total_class):\n",
    "    tn_cases[each] = tp_cases.sum() - tp_cases[each]\n",
    "    fn_cases[each] = total_cases.sum() - (tn_cases[each] + fp_cases[each] + tp_cases[each]) \n",
    "    \n",
    "print(tn_cases)    \n",
    "print(fn_cases)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-soviet",
   "metadata": {},
   "source": [
    "tn_cases =  np.zeros([total_class], dtype = int)\n",
    "\n",
    "for row in range(0, total_class):\n",
    "    sum = 0;\n",
    "    for column in range(0, total_class):\n",
    "        if column == row:\n",
    "            continue\n",
    "        sum = sum + fp_cases[column]\n",
    "    tn_cases[row] = sum\n",
    "    \n",
    "print(tn_cases)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-affair",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/fbeta-measure-for-machine-learning/\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
