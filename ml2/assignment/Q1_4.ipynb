{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c41a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "\n",
    "class Q1_4:\n",
    "\n",
    "    def __init__(self, img_dim_x=224, img_dim_y=224, img_rgb=3, img_folder='/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/'):\n",
    "        self.img_dim_x = img_dim_x\n",
    "        self.img_dim_y = img_dim_y\n",
    "        self.img_rgb = img_rgb\n",
    "        self.img_dim = [img_dim_x, img_dim_y]\n",
    "        self.img_folder = img_folder\n",
    "\n",
    "    def execute(self):\n",
    "        vgg19 = VGG19(weights='imagenet')\n",
    "        vgg19.summary()\n",
    "\n",
    "        model = Model(inputs=vgg19.input,\n",
    "                      outputs=vgg19.get_layer('fc2').output)\n",
    "\n",
    "        # useful for getting number of output classes\n",
    "        abs_path = sys.path[0]\n",
    "        base_name = os.path.dirname(abs_path)\n",
    "        img_path = os.path.join(base_name, 'assignment/VOCdevkit/VOC2012/JPEGImages1/2007_000027.jpg')\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(self.img_dim_x, self.img_dim_y))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        block_pool_features = model.predict(x)\n",
    "        print(block_pool_features.shape)\n",
    "        print(block_pool_features)\n",
    "\n",
    "    def execute_many(self):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        vgg19 = VGG19(weights='imagenet')\n",
    "        vgg19.summary()\n",
    "\n",
    "        model = Model(inputs=vgg19.input,\n",
    "                      outputs=vgg19.get_layer('fc2').output)\n",
    "\n",
    "        labels = []\n",
    "        features = []\n",
    "        # useful for getting number of output classes\n",
    "        img_dict = self.read()\n",
    "        img_paths = img_dict['img_path']\n",
    "        xml_paths = img_dict['xml_path']\n",
    "        for index in range(0, len(img_paths)):\n",
    "            img = image.load_img(img_paths[index], target_size=(self.img_dim_x, self.img_dim_y))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            block_pool_features = model.predict(x)\n",
    "            flat_pool_features = block_pool_features.flatten()\n",
    "            features.append(flat_pool_features)\n",
    "            labels.append(ElementTree.parse(xml_paths[index]).getroot().find('.//object').find('name').text)\n",
    "            #objects = ElementTree.parse(xml_paths[index]).getroot().findall('.//object')\n",
    "            #label = []\n",
    "            #[label.append(each.find('name').text) for each in objects]\n",
    "            #labels.append(list(dict.fromkeys(label)))\n",
    "        # print(labels)\n",
    "        # print(len(features))\n",
    "        #flat_list = [item for sublist in labels for item in sublist]\n",
    "\n",
    "        print(len(features[0]))\n",
    "        print(\"features: {}\".format(features))\n",
    "        print(\"labels: {}\".format(labels))\n",
    "        print(\"unique labels: {}\".format(list(set(labels))))\n",
    "\n",
    "        le_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "        # get the shape of training labels\n",
    "        print(\"encoded labels: {}\".format(le_labels))\n",
    "        print(\"features shape: {}\".format(np.array(features).shape))\n",
    "        print(\"encoded labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(np.array(features),\n",
    "                                                                              np.array(le_labels),\n",
    "                                                                              test_size=0.3,\n",
    "                                                                              random_state=100)\n",
    "\n",
    "        print(\"splitted data...\")\n",
    "        print(\"train data  : {}\".format(X_train.shape))\n",
    "        print(\"test data   : {}\".format(X_test.shape))\n",
    "        print(\"train labels: {}\".format(y_train.shape))\n",
    "        print(\"test labels : {}\".format(y_test.shape))\n",
    "\n",
    "        # use logistic regression as the model\n",
    "        #model = OneVsRestClassifier(SVC())\n",
    "        #model.fit(np.array(features), np.array(le_labels))\n",
    "        #print(\"created SVM model\")\n",
    "\n",
    "        # Creating the SVM model\n",
    "        model = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "        # Fitting the model with training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Making a prediction on the test set\n",
    "        prediction = model.predict(X_test)\n",
    "\n",
    "        # Evaluating the model\n",
    "        print(\"Test Set Accuracy : {}\".format(accuracy_score(y_test, prediction)))\n",
    "        print(\"Classification Report : {}\".format(classification_report(y_test, prediction)))\n",
    "\n",
    "    def read(self):\n",
    "        img_dict = {'img_path': self.read_image(), 'xml_path': self.read_annotation()}\n",
    "        return img_dict\n",
    "\n",
    "    def read_annotation(self):\n",
    "        #abs_path = sys.path[0]\n",
    "        #base_name = os.path.dirname(abs_path)\n",
    "        img_files = self.read_image()\n",
    "        xml_files = []\n",
    "        for file in img_files:\n",
    "            filename = Path(file).stem\n",
    "            xml_dir = os.path.join(self.img_folder, 'Annotations/')\n",
    "            xml_file = xml_dir + filename + \".xml\"\n",
    "            xml_files.append(xml_file)\n",
    "\n",
    "        return xml_files\n",
    "\n",
    "    def read_path(self):\n",
    "        files = self.read_image()\n",
    "        for file in files:\n",
    "            print(Path(file).stem)\n",
    "\n",
    "    def read_image(self):\n",
    "        #abs_path = sys.path[0]\n",
    "        #base_name = os.path.dirname(abs_path)\n",
    "        img_dir = os.path.join( self.img_folder ,'JPEGImages2/')\n",
    "        ext = ['png', 'jpg', 'gif']\n",
    "        files = []\n",
    "        [files.extend(glob.glob(img_dir + '*.' + e)) for e in ext]\n",
    "        return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1d8464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4096\n",
      "features: [array([-0.        ,  2.0118582 ,  0.41150683, ...,  0.19820923,\n",
      "        1.1877387 ,  0.81167275], dtype=float32), array([-0.       ,  3.0575397, -0.       , ...,  4.2556543, -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0.      , -0.      , -0.      , ...,  2.832628, -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        0.77378833, -0.        ], dtype=float32), array([-0.      , -0.      , 10.256748, ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0.       ,  3.3205798,  3.9630134, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       ,  0.8174509,  3.6397483, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([ 0.0310145,  2.2455053,  2.0111756, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       , -0.       ,  7.9392548, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       , -0.       , -0.       , ..., -0.       ,  1.8538382,\n",
      "        0.6391779], dtype=float32), array([-0.        ,  3.4810836 ,  0.96469885, ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([-0.       , -0.       , -0.       , ..., -0.       ,  1.1291082,\n",
      "        2.5243485], dtype=float32), array([-0.        ,  1.0841932 , -0.        , ..., -0.        ,\n",
      "        0.29764637, -0.        ], dtype=float32), array([-0.       , -0.       ,  0.9496654, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       , -0.       ,  2.7536175, ..., -0.       ,  2.676375 ,\n",
      "       -0.       ], dtype=float32), array([-0.      , -0.      , -0.      , ...,  2.094533, -0.      ,\n",
      "       -0.      ], dtype=float32), array([ 8.32316  , -0.       , -0.       , ..., -0.       ,  4.6332517,\n",
      "        1.208823 ], dtype=float32)]\n",
      "labels: ['diningtable', 'boat', 'train', 'train', 'bird', 'aeroplane', 'tvmonitor', 'aeroplane', 'aeroplane', 'aeroplane', 'person', 'tvmonitor', 'bottle', 'tvmonitor', 'sheep', 'dog', 'boat', 'bicycle']\n",
      "unique labels: ['bottle', 'train', 'aeroplane', 'dog', 'diningtable', 'sheep', 'person', 'boat', 'tvmonitor', 'bird', 'bicycle']\n",
      "encoded labels: [ 5  3  9  9  2  0 10  0  0  0  7 10  4 10  8  6  3  1]\n",
      "features shape: (18, 4096)\n",
      "encoded labels shape: (18,)\n",
      "splitted data...\n",
      "train data  : (12, 4096)\n",
      "test data   : (6, 4096)\n",
      "train labels: (12,)\n",
      "test labels : (6,)\n",
      "Test Set Accuracy : 0.5\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "          10       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.27      0.40      0.30         6\n",
      "weighted avg       0.39      0.50      0.42         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = Q1_4()\n",
    "q1.execute_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbed2917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "\n",
    "class Q1_4:\n",
    "\n",
    "    def __init__(self, img_dim_x=224, img_dim_y=224, img_rgb=3, img_folder='/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/'):\n",
    "        self.img_dim_x = img_dim_x\n",
    "        self.img_dim_y = img_dim_y\n",
    "        self.img_rgb = img_rgb\n",
    "        self.img_dim = [img_dim_x, img_dim_y]\n",
    "        self.img_folder = img_folder\n",
    "\n",
    "    def execute(self):\n",
    "        vgg19 = VGG19(weights='imagenet')\n",
    "        vgg19.summary()\n",
    "\n",
    "        model = Model(inputs=vgg19.input,\n",
    "                      outputs=vgg19.get_layer('fc2').output)\n",
    "\n",
    "        # useful for getting number of output classes\n",
    "        abs_path = sys.path[0]\n",
    "        base_name = os.path.dirname(abs_path)\n",
    "        img_path = os.path.join(base_name, 'assignment/VOCdevkit/VOC2012/JPEGImages1/2007_000027.jpg')\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(self.img_dim_x, self.img_dim_y))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        block_pool_features = model.predict(x)\n",
    "        print(block_pool_features.shape)\n",
    "        print(block_pool_features)\n",
    "\n",
    "    def execute_many(self):\n",
    "        warnings.filterwarnings('ignore')\n",
    "        vgg19 = VGG19(weights='imagenet')\n",
    "        vgg19.summary()\n",
    "\n",
    "        model = Model(inputs=vgg19.input,\n",
    "                      outputs=vgg19.get_layer('fc2').output)\n",
    "\n",
    "        labels = []\n",
    "        features = []\n",
    "        # useful for getting number of output classes\n",
    "        img_dict = self.read()\n",
    "        img_paths = img_dict['img_path']\n",
    "        xml_paths = img_dict['xml_path']\n",
    "        for index in range(0, len(img_paths)):\n",
    "            img = image.load_img(img_paths[index], target_size=(self.img_dim_x, self.img_dim_y))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            block_pool_features = model.predict(x)\n",
    "            flat_pool_features = block_pool_features.flatten()\n",
    "            features.append(flat_pool_features)\n",
    "            labels.append(ElementTree.parse(xml_paths[index]).getroot().find('.//object').find('name').text)\n",
    "            #objects = ElementTree.parse(xml_paths[index]).getroot().findall('.//object')\n",
    "            #label = []\n",
    "            #[label.append(each.find('name').text) for each in objects]\n",
    "            #labels.append(list(dict.fromkeys(label)))\n",
    "        # print(labels)\n",
    "        # print(len(features))\n",
    "        #flat_list = [item for sublist in labels for item in sublist]\n",
    "\n",
    "        print(len(features[0]))\n",
    "        print(\"features: {}\".format(features))\n",
    "        print(\"labels: {}\".format(labels))\n",
    "        print(\"unique labels: {}\".format(list(set(labels))))\n",
    "\n",
    "        le_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "        # get the shape of training labels\n",
    "        print(\"encoded labels: {}\".format(le_labels))\n",
    "        print(\"features shape: {}\".format(np.array(features).shape))\n",
    "        print(\"encoded labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(np.array(features),\n",
    "                                                                              np.array(le_labels),\n",
    "                                                                              test_size=0.3,\n",
    "                                                                              random_state=100)\n",
    "\n",
    "        print(\"splitted data...\")\n",
    "        print(\"train data  : {}\".format(X_train.shape))\n",
    "        print(\"test data   : {}\".format(X_test.shape))\n",
    "        print(\"train labels: {}\".format(y_train.shape))\n",
    "        print(\"test labels : {}\".format(y_test.shape))\n",
    "\n",
    "        # use logistic regression as the model\n",
    "        #model = OneVsRestClassifier(SVC())\n",
    "        #model.fit(np.array(features), np.array(le_labels))\n",
    "        #print(\"created SVM model\")\n",
    "\n",
    "        # Creating the SVM model\n",
    "        model = OneVsRestClassifier(SVC())\n",
    "\n",
    "        # Fitting the model with training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Making a prediction on the test set\n",
    "        prediction = model.predict(X_test)\n",
    "\n",
    "        # Evaluating the model\n",
    "        print(\"Test Set Accuracy : {}\".format(accuracy_score(y_test, prediction)))\n",
    "        print(\"Classification Report : {}\".format(classification_report(y_test, prediction)))\n",
    "        print(multilabel_confusion_matrix(y_test, prediction))\n",
    "\n",
    "    def read(self):\n",
    "        img_dict = {'img_path': self.read_image(), 'xml_path': self.read_annotation()}\n",
    "        return img_dict\n",
    "\n",
    "    def read_annotation(self):\n",
    "        #abs_path = sys.path[0]\n",
    "        #base_name = os.path.dirname(abs_path)\n",
    "        img_files = self.read_image()\n",
    "        xml_files = []\n",
    "        for file in img_files:\n",
    "            filename = Path(file).stem\n",
    "            xml_dir = os.path.join(self.img_folder, 'Annotations/')\n",
    "            xml_file = xml_dir + filename + \".xml\"\n",
    "            xml_files.append(xml_file)\n",
    "\n",
    "        return xml_files\n",
    "\n",
    "    def read_path(self):\n",
    "        files = self.read_image()\n",
    "        for file in files:\n",
    "            print(Path(file).stem)\n",
    "\n",
    "    def read_image(self):\n",
    "        #abs_path = sys.path[0]\n",
    "        #base_name = os.path.dirname(abs_path)\n",
    "        img_dir = os.path.join( self.img_folder ,'JPEGImages2/')\n",
    "        ext = ['png', 'jpg', 'gif']\n",
    "        files = []\n",
    "        [files.extend(glob.glob(img_dir + '*.' + e)) for e in ext]\n",
    "        return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f4a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4096\n",
      "features: [array([ 5.3971524, -0.       ,  2.7153337, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([ 0.71897113, -0.        , -0.        , ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([-0.        ,  2.0118582 ,  0.41150683, ...,  0.19820923,\n",
      "        1.1877387 ,  0.81167275], dtype=float32), array([-0.       , -0.       ,  1.5629687, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       ,  3.0575397, -0.       , ...,  4.2556543, -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0.      , -0.      ,  8.525439, ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        0.06154042, -0.        ], dtype=float32), array([-0.      , -0.      , -0.      , ...,  2.832628, -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        0.77378833, -0.        ], dtype=float32), array([-0.      , -0.      , 10.256748, ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([-0.       ,  3.3205798,  3.9630134, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       ,  0.6754836, -0.       , ..., -0.       , -0.       ,\n",
      "        1.7339633], dtype=float32), array([-0.       ,  0.8174509,  3.6397483, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([ 0.0310145,  2.2455053,  2.0111756, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([ 0.64238286, -0.        , -0.        , ...,  0.15693933,\n",
      "       -0.        ,  3.886952  ], dtype=float32), array([-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        0.8312464 ,  0.73167723], dtype=float32), array([-0.       , -0.       ,  7.9392548, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       , -0.       , -0.       , ..., -0.       ,  1.8538382,\n",
      "        0.6391779], dtype=float32), array([-0.       , -0.       ,  2.3424613, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.        ,  3.4810836 ,  0.96469885, ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([ 1.2797384, -0.       , -0.       , ..., -0.       ,  4.233828 ,\n",
      "        4.7184076], dtype=float32), array([ 2.9744945 ,  0.38783985, -0.        , ..., -0.        ,\n",
      "        1.6178968 ,  1.8963082 ], dtype=float32), array([ 1.7551367, -0.       , -0.       , ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        0.09992504, -0.        ], dtype=float32), array([-0.       , -0.       , -0.       , ..., -0.       ,  1.1291082,\n",
      "        2.5243485], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([-0.        ,  1.0841932 , -0.        , ..., -0.        ,\n",
      "        0.29764637, -0.        ], dtype=float32), array([-0.       ,  1.4643617,  5.8899055, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.        , -0.        ,  2.726179  , ..., -0.        ,\n",
      "       -0.        ,  0.97423023], dtype=float32), array([-0.       , -0.       ,  0.9496654, ..., -0.       , -0.       ,\n",
      "       -0.       ], dtype=float32), array([-0.       , -0.       , -0.       , ..., -0.       , -0.       ,\n",
      "        2.1348562], dtype=float32), array([-0.        , -0.        ,  4.040072  , ..., -0.        ,\n",
      "        0.31219202, -0.        ], dtype=float32), array([-0.      ,  2.535326, -0.      , ..., -0.      , -0.      ,\n",
      "       -0.      ], dtype=float32), array([ 0.52207994,  2.2570357 , -0.        , ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([ 0.1875982 , -0.        ,  0.47079235, ..., -0.        ,\n",
      "       -0.        , -0.        ], dtype=float32), array([-0.       , -0.       ,  2.7536175, ..., -0.       ,  2.676375 ,\n",
      "       -0.       ], dtype=float32), array([-0.      , -0.      , -0.      , ...,  2.094533, -0.      ,\n",
      "       -0.      ], dtype=float32), array([ 8.32316  , -0.       , -0.       , ..., -0.       ,  4.6332517,\n",
      "        1.208823 ], dtype=float32), array([-0., -0., -0., ..., -0., -0., -0.], dtype=float32), array([ 3.270454  , -0.        , -0.        , ..., -0.        ,\n",
      "        0.05163676, -0.        ], dtype=float32)]\n",
      "labels: ['train', 'horse', 'diningtable', 'person', 'boat', 'train', 'bird', 'sofa', 'cow', 'train', 'bird', 'aeroplane', 'tvmonitor', 'person', 'aeroplane', 'aeroplane', 'person', 'horse', 'aeroplane', 'person', 'train', 'tvmonitor', 'bottle', 'bicycle', 'train', 'motorbike', 'bottle', 'cat', 'tvmonitor', 'bottle', 'bird', 'sheep', 'bicycle', 'cat', 'person', 'bicycle', 'boat', 'dog', 'boat', 'bicycle', 'cow', 'cow']\n",
      "unique labels: ['bottle', 'train', 'sofa', 'aeroplane', 'horse', 'dog', 'diningtable', 'cow', 'sheep', 'cat', 'person', 'boat', 'tvmonitor', 'motorbike', 'bird', 'bicycle']\n",
      "encoded labels: [14  9  7 11  3 14  2 13  6 14  2  0 15 11  0  0 11  9  0 11 14 15  4  1\n",
      " 14 10  4  5 15  4  2 12  1  5 11  1  3  8  3  1  6  6]\n",
      "features shape: (42, 4096)\n",
      "encoded labels shape: (42,)\n",
      "splitted data...\n",
      "train data  : (29, 4096)\n",
      "test data   : (13, 4096)\n",
      "train labels: (29,)\n",
      "test labels : (13,)\n",
      "Test Set Accuracy : 0.38461538461538464\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       1.00      0.67      0.80         3\n",
      "          15       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.38        13\n",
      "   macro avg       0.33      0.31      0.32        13\n",
      "weighted avg       0.46      0.38      0.42        13\n",
      "\n",
      "[[[12  0]\n",
      "  [ 0  1]]\n",
      "\n",
      " [[11  0]\n",
      "  [ 2  0]]\n",
      "\n",
      " [[12  0]\n",
      "  [ 0  1]]\n",
      "\n",
      " [[11  0]\n",
      "  [ 2  0]]\n",
      "\n",
      " [[12  1]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[12  0]\n",
      "  [ 1  0]]\n",
      "\n",
      " [[12  0]\n",
      "  [ 1  0]]\n",
      "\n",
      " [[12  1]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[ 7  6]\n",
      "  [ 0  0]]\n",
      "\n",
      " [[12  0]\n",
      "  [ 1  0]]\n",
      "\n",
      " [[10  0]\n",
      "  [ 1  2]]\n",
      "\n",
      " [[12  0]\n",
      "  [ 0  1]]]\n"
     ]
    }
   ],
   "source": [
    "q1 = Q1_4()\n",
    "q1.execute_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40d574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8592283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d86d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0930e46df0d1b93ecf8fe51f04b6e478dce688000f1283825e61bc5e483dc45d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
