{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] CATEGORIES ARE IN \n",
      " /Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories'\n",
    "valid_exts = [\".jpg\", \".gif\", \".png\", \".jpeg\"]\n",
    "print (\"[%d] CATEGORIES ARE IN \\n %s\" % (len(os.listdir(path)), path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num imgs: 60\n",
      "Num labels: 60\n",
      "10\n",
      "{'accordion': 0, 'airplanes': 1, 'anchor': 2, 'ant': 3, 'bass': 4, 'beaver': 5, 'binocular': 6, 'bonsai': 7, 'buddha': 8, 'butterfly': 9}\n"
     ]
    }
   ],
   "source": [
    "categories = sorted(os.listdir(path))\n",
    "ncategories = len(categories)\n",
    "imgs = []\n",
    "labels = []\n",
    "cat_dict = {}\n",
    "# LOAD ALL IMAGES \n",
    "for i, category in enumerate(categories):\n",
    "    iter = 0\n",
    "    for f in os.listdir(path + \"/\" + category):\n",
    "        if iter == 0:\n",
    "            ext = os.path.splitext(f)[1]\n",
    "            if ext.lower() not in valid_exts:\n",
    "                continue\n",
    "            fullpath = os.path.join(path + \"/\" + category, f)\n",
    "            img = load_img(fullpath, target_size=(200, 300))\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            imgs.append(img) # NORMALIZE IMAGE \n",
    "            label_curr = i\n",
    "            labels.append(label_curr)\n",
    "            cat_dict[category] = i\n",
    "        #iter = (iter+1)%10;\n",
    "print (\"Num imgs: %d\" % (len(imgs)))\n",
    "print (\"Num labels: %d\" % (len(labels)) )\n",
    "print (ncategories)\n",
    "print(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size = 0.2) # Change the proportion of training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     [(None, 200, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              113250304 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 148,843,304\n",
      "Trainable params: 148,843,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "#model_vgg16_conv.summary()\n",
    "\n",
    "#Create your own input format (here 3x200x200)\n",
    "ip = Input(shape=(200,300,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(ip)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(inputs=ip, outputs=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool_table (89.63%)\n",
      "acorn (33.88%)\n",
      "polecat (61.36%)\n",
      "acorn (90.27%)\n",
      "medicine_chest (59.50%)\n",
      "hook (66.87%)\n",
      "howler_monkey (100.00%)\n",
      "mitten (92.76%)\n",
      "oystercatcher (70.69%)\n",
      "howler_monkey (62.04%)\n",
      "oystercatcher (99.68%)\n",
      "howler_monkey (67.06%)\n",
      "bobsled (98.12%)\n",
      "wallet (45.95%)\n",
      "acorn (61.60%)\n",
      "oystercatcher (81.44%)\n",
      "ice_cream (95.96%)\n",
      "oystercatcher (93.72%)\n",
      "pool_table (59.05%)\n",
      "agama (29.88%)\n",
      "echidna (95.71%)\n",
      "bobsled (99.85%)\n",
      "howler_monkey (97.34%)\n",
      "coyote (97.83%)\n",
      "sea_cucumber (44.24%)\n",
      "Yorkshire_terrier (99.43%)\n",
      "howler_monkey (97.19%)\n",
      "Yorkshire_terrier (70.22%)\n",
      "bobsled (91.37%)\n",
      "coho (56.70%)\n",
      "acorn (68.24%)\n",
      "monarch (99.07%)\n",
      "European_gallinule (62.35%)\n",
      "oystercatcher (96.14%)\n",
      "howler_monkey (30.06%)\n",
      "parking_meter (91.08%)\n",
      "oystercatcher (100.00%)\n",
      "lotion (76.78%)\n",
      "Eskimo_dog (53.07%)\n",
      "Eskimo_dog (88.16%)\n",
      "cab (84.36%)\n",
      "papillon (59.77%)\n",
      "pool_table (99.24%)\n",
      "howler_monkey (99.50%)\n",
      "howler_monkey (98.59%)\n",
      "Yorkshire_terrier (34.80%)\n",
      "howler_monkey (75.80%)\n",
      "bobsled (54.46%)\n"
     ]
    }
   ],
   "source": [
    "temp_labels = []\n",
    "temp_features = []\n",
    "\n",
    "for index in range(0, len(X_train)):\n",
    "    img = X_train[index]\n",
    "    img = preprocess_input(img)\n",
    "    # Extracting features\n",
    "    yhat = my_model.predict(img)\n",
    "    # convert the probabilities to class labels\n",
    "    label = decode_predictions(yhat)\n",
    "    # retrieve the most likely result, e.g. highest probability\n",
    "    label = label[0][0]\n",
    "    # print the classification\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a3d548f502a1be5de78167d3c8bbbe486d7de873446eacc88061a7145adfcaf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('python3_6_13': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
