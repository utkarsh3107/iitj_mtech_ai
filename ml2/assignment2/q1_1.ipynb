{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#from keras.datasets import cifar100\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "#from keras import optimizers\n",
    "import numpy as np\n",
    "#from keras.layers.core import Lambda\n",
    "#from keras.constraints import maxnorm\n",
    "#from keras.optimizers import SGD\n",
    "#from keras import backend as K\n",
    "#from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread as imaread\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "weight_decay = 0.0005\n",
    "x_shape = [32,32,3]\n",
    "\n",
    "def imread(path):\n",
    "    img = imaread(path).astype(np.float)\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.transpose(np.array([img, img, img]), (2, 0, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] CATEGORIES ARE IN \n",
      " /Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories'\n",
    "valid_exts = [\".jpg\", \".gif\", \".png\", \".jpeg\"]\n",
    "print (\"[%d] CATEGORIES ARE IN \\n %s\" % (len(os.listdir(path)), path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num imgs: 60\n",
      "Num labels: 60\n",
      "10\n",
      "{'accordion': 0, 'airplanes': 1, 'anchor': 2, 'ant': 3, 'bass': 4, 'beaver': 5, 'binocular': 6, 'bonsai': 7, 'buddha': 8, 'butterfly': 9}\n"
     ]
    }
   ],
   "source": [
    "categories = sorted(os.listdir(path))\n",
    "ncategories = len(categories)\n",
    "imgs = []\n",
    "labels = []\n",
    "cat_dict = {}\n",
    "# LOAD ALL IMAGES \n",
    "for i, category in enumerate(categories):\n",
    "    iter = 0\n",
    "    for f in os.listdir(path + \"/\" + category):\n",
    "        if iter == 0:\n",
    "            ext = os.path.splitext(f)[1]\n",
    "            if ext.lower() not in valid_exts:\n",
    "                continue\n",
    "            fullpath = os.path.join(path + \"/\" + category, f)\n",
    "            img = np.array(Image.fromarray(imread(fullpath), \"RGB\").resize((224, 224)))\n",
    "            img = img.astype('float32')\n",
    "            #img[:,:,0] -= 123.68\n",
    "            #img[:,:,1] -= 116.78\n",
    "            #img[:,:,2] -= 103.94\n",
    "            imgs.append(img) # NORMALIZE IMAGE \n",
    "            label_curr = i\n",
    "            labels.append(label_curr)\n",
    "            cat_dict[category] = i\n",
    "        #iter = (iter+1)%10;\n",
    "print (\"Num imgs: %d\" % (len(imgs)))\n",
    "print (\"Num labels: %d\" % (len(labels)) )\n",
    "print (ncategories)\n",
    "print(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs, labels, test_size = 0.2) # Change the proportion of training and test\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "y_train = np.stack(y_train, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "y_test = np.stack(y_test, axis=0)\n",
    "# print (\"Num train_imgs: %d\" % (len(X_train))) # 8229 when test_size = 0.1\n",
    "# print (\"Num test_imgs: %d\" % (len(X_test))) # 915 when test_size = 0.1\n",
    "# # one hot encode outputs - change the single value into a vector with (number of categories) dimensions\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes= y_test.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "data['categories'] = categories\n",
    "data['X_train'] = X_train\n",
    "data['y_train'] = y_train\n",
    "data['X_test'] = X_test\n",
    "data['y_test'] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-d295ff55647a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtemp_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# convert the probabilities to class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_pool_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# retrieve the most likely result, e.g. highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6_13/lib/python3.6/site-packages/tensorflow_core/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6_13/lib/python3.6/site-packages/tensorflow_core/python/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/python3_6_13/lib/python3.6/site-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                          \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                          \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
      "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 4096)"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define model\n",
    "vgg16 = VGG16(weights='imagenet')\n",
    "#vgg16.summary()\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Extracrting last leayer from the teh CNN model before the rediction layer\n",
    "model = Model(inputs=vgg16.input, outputs=vgg16.get_layer('fc2').output)\n",
    "temp_labels = []\n",
    "temp_features = []\n",
    "\n",
    "\n",
    "for index in range(0, len(X_train)):\n",
    "    x = X_train[index]\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # Extracting features\n",
    "    block_pool_features = model.predict(x)\n",
    "    temp_labels.append(y_train[index])\n",
    "    # convert the probabilities to class labels\n",
    "    label = decode_predictions(block_pool_features)\n",
    "    # retrieve the most likely result, e.g. highest probability\n",
    "    label = label[0][0]\n",
    "    # print the classification\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "\n",
    "    flat_pool_features = block_pool_features.flatten()\n",
    "    temp_features.append(flat_pool_features)\n",
    "\n",
    "\n",
    "# Each image can have multiple labels assigned to it. Assigning identical labels to the new features.\n",
    "#print(temp_features)\n",
    "#print(temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-97162d2dcb88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#image = img_to_array(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# reshape data for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# prepare the image for the VGG model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load the model\n",
    "model = VGG16()\n",
    "# load an image from file\n",
    "#image = load_img('mug.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "#image = img_to_array(image)\n",
    "# reshape data for the model\n",
    "img = img.reshape((1, X_train[0][0], X_train[0][1], X_train[0][2]))\n",
    "# prepare the image for the VGG model\n",
    "img = preprocess_input(img)\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(img)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 40.,  47., 117.],\n",
       "         [ 39.,  46., 116.],\n",
       "         [ 38.,  45., 115.],\n",
       "         ...,\n",
       "         [ 37.,  45., 110.],\n",
       "         [ 38.,  46., 111.],\n",
       "         [ 38.,  46., 111.]],\n",
       "\n",
       "        [[ 40.,  47., 117.],\n",
       "         [ 39.,  46., 116.],\n",
       "         [ 38.,  45., 115.],\n",
       "         ...,\n",
       "         [ 36.,  44., 109.],\n",
       "         [ 36.,  44., 109.],\n",
       "         [ 36.,  44., 109.]],\n",
       "\n",
       "        [[ 40.,  47., 117.],\n",
       "         [ 39.,  46., 116.],\n",
       "         [ 38.,  45., 115.],\n",
       "         ...,\n",
       "         [ 36.,  44., 109.],\n",
       "         [ 36.,  44., 109.],\n",
       "         [ 36.,  44., 109.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 23.,  34.,  98.],\n",
       "         [ 33.,  44., 108.],\n",
       "         [ 30.,  41., 105.],\n",
       "         ...,\n",
       "         [ 30.,  43.,  98.],\n",
       "         [ 29.,  42.,  97.],\n",
       "         [ 24.,  37.,  92.]],\n",
       "\n",
       "        [[ 23.,  34.,  98.],\n",
       "         [ 33.,  44., 108.],\n",
       "         [ 30.,  41., 105.],\n",
       "         ...,\n",
       "         [ 30.,  43.,  98.],\n",
       "         [ 29.,  42.,  97.],\n",
       "         [ 24.,  37.,  92.]],\n",
       "\n",
       "        [[ 23.,  34.,  98.],\n",
       "         [ 33.,  44., 108.],\n",
       "         [ 30.,  41., 105.],\n",
       "         ...,\n",
       "         [ 26.,  39.,  92.],\n",
       "         [ 25.,  38.,  91.],\n",
       "         [ 21.,  34.,  89.]]]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories/bass/image_0001.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "img = preprocess_input(img)\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(img)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goldfish (86.72%)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "img = load_img('/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment2/101_ObjectCategories/bass/image_0001.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "img = preprocess_input(img)\n",
    "# predict the probability across all output classes\n",
    "yhat = model.predict(img)\n",
    "# convert the probabilities to class labels\n",
    "label = decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "label = label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a3d548f502a1be5de78167d3c8bbbe486d7de873446eacc88061a7145adfcaf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('python3_6_13': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
