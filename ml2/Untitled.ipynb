{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56ed354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pickle import dump\n",
    "\n",
    "# other imports\n",
    "from xml.etree import ElementTree\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0c63e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten_1/Reshape:0\", shape=(None, None), dtype=float32)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoding labels.\n",
      "features: [array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([ 0.      ,  0.      ,  0.      , ...,  0.      , 17.909626,\n",
      "        0.      ], dtype=float32), array([ 0.      ,  0.      ,  0.      , ...,  0.      , 17.611933,\n",
      "        0.      ], dtype=float32), array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), array([ 0.      ,  0.      ,  0.      , ...,  8.178619, 12.299476,\n",
      "        0.      ], dtype=float32), array([ 0.      ,  0.      ,  0.      , ...,  0.      , 11.184828,\n",
      "        0.      ], dtype=float32)]\n",
      "labels: ['train', 'aeroplane', 'aeroplane', 'person', 'tvmonitor', 'boat']\n",
      "unique labels: ['person', 'aeroplane', 'train', 'boat', 'tvmonitor']\n",
      "encoded labels: [3 0 0 2 4 1]\n",
      "features shape: (6, 25088)\n",
      "encoded labels shape: (6,)\n",
      "splitted data...\n",
      "train data  : (4, 25088)\n",
      "test data   : (2, 25088)\n",
      "train labels: (4,)\n",
      "test labels : (2,)\n",
      "created SVM model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7ae9c3322d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"created SVM model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0margmaxima\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxima\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxima\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0margmaxima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaxima\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# probabilities of the positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0mof\u001b[0m \u001b[0movo\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \"\"\"\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ovr'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# NOTE: _validate_for_predict contains check for is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# hence must be placed before any other attributes are used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m--> 475\u001b[0;31m                             order=\"C\", accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 717\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# Default input size for VGG16\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "no_of_channels_in_rgb = 3\n",
    "image_size = (224, 224)\n",
    "# load model without classifier layers\n",
    "base_model = VGG19(weights='imagenet',include_top=False, input_shape=(img_width, img_height, no_of_channels_in_rgb))\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(base_model.layers[-1].output)\n",
    "print(flat1)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(20, activation='softmax')(class1)\n",
    "# define new model\n",
    "pre_trained_model = Model(inputs=base_model.inputs, outputs=flat1)\n",
    "# summarize\n",
    "pre_trained_model.summary()\n",
    "\n",
    "#train_labels = [['person',1],['aeroplane',2],['tvmonitor',3],['train',4],['boat',5],['dog',6],['chair',7],['bird',8],['bicycle',9],['bottle',10],['diningtable',11],['sheep','horse',12],['sofa',13],['cat',14]]\n",
    "#train_labels = ['person','aeroplane','tvmonitor','train','boat','dog','chair','bird','bicycle','bottle','diningtable','sheep','horse','sofa','cat']\n",
    "#train_labels = ['person','aeroplane','tvmonitor','train','boat','dog','chair','bird','bicycle','bottle']\n",
    "\n",
    "# encode the labels\n",
    "print(\"encoding labels.\")\n",
    "le = LabelEncoder()\n",
    "#le_labels = le.fit_transform(train_labels)\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, file in enumerate(os.listdir(\"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/JPEGImages1\")):\n",
    "  name = file.split(\".\")\n",
    "  image_path = \"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/JPEGImages1/\" + name[0]+\".jpg\"\n",
    "  annotation_path = \"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/Annotations/\" + name[0]+\".xml\"\n",
    "  #print(file)\n",
    "  #print(annotation_path)\n",
    "  #print('image_path')\n",
    "  #print(image_path)\n",
    "  img = image.load_img(image_path, target_size=image_size)\n",
    "  # Converts a PIL Image to 3D Numy Array\n",
    "  # Adding the fouth dimension, for number of images\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  feature = pre_trained_model.predict(x)\n",
    "  flat = feature.flatten()\n",
    "  features.append(flat)\n",
    "  tree = ElementTree.parse(annotation_path)\n",
    "  #get the root of the document\n",
    "  root = tree.getroot()\n",
    "  objects=root.find('.//object')\n",
    "  label=objects.find('name').text\n",
    "  labels.append(label)\n",
    "  count += 1\n",
    "\n",
    "print(\"features: {}\".format(features))\n",
    "print(\"labels: {}\".format(labels))\n",
    "print(\"unique labels: {}\".format(list(set(labels))))\n",
    "\n",
    "le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "print(\"encoded labels: {}\".format(le_labels))\n",
    "print(\"features shape: {}\".format(np.array(features).shape))\n",
    "print(\"encoded labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(le_labels),\n",
    "                                                                  test_size=0.3,\n",
    "                                                                  random_state=100)\n",
    "\n",
    "print(\"splitted data...\")\n",
    "print(\"train data  : {}\".format(train_data.shape))\n",
    "print(\"test data   : {}\".format(test_data.shape))\n",
    "print(\"train labels: {}\".format(train_labels.shape))\n",
    "print(\"test labels : {}\".format(test_labels.shape))\n",
    "\n",
    "# use logistic regression as the model\n",
    "model = OneVsRestClassifier(SVC())\n",
    "model.fit(np.array(features), np.array(le_labels))\n",
    "print(\"created SVM model\")\n",
    "y=model.predict(x)\n",
    "label = decode_predictions(y)\n",
    "label = label[0][0]\n",
    "print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "\n",
    "\n",
    "#y = np.array([0, 0, 1, 1, 2, 2])\n",
    "#clf = OneVsRestClassifier(SVC()).fit(, le_labels)\n",
    "#clf.predict([[-19, -20], [9, 9], [-5, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b5ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten_4/Reshape:0\", shape=(None, None), dtype=float32)\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "encoding labels.\n",
      "[[[230. 231. 233.]\n",
      "  [231. 232. 234.]\n",
      "  [229. 233. 234.]\n",
      "  ...\n",
      "  [ 23.  34.  36.]\n",
      "  [ 23.  35.  33.]\n",
      "  [ 26.  38.  36.]]\n",
      "\n",
      " [[234. 229. 233.]\n",
      "  [232. 230. 233.]\n",
      "  [232. 232. 234.]\n",
      "  ...\n",
      "  [ 27.  41.  44.]\n",
      "  [ 33.  43.  45.]\n",
      "  [ 34.  44.  46.]]\n",
      "\n",
      " [[234. 229. 233.]\n",
      "  [232. 230. 233.]\n",
      "  [233. 231. 234.]\n",
      "  ...\n",
      "  [ 16.  44.  47.]\n",
      "  [ 25.  46.  49.]\n",
      "  [ 21.  42.  45.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 22.  21.  19.]\n",
      "  [ 24.  18.  18.]\n",
      "  [ 26.  18.  16.]\n",
      "  ...\n",
      "  [ 16.  16.  16.]\n",
      "  [ 18.  18.  20.]\n",
      "  [ 17.  17.  19.]]\n",
      "\n",
      " [[ 28.  27.  25.]\n",
      "  [ 30.  25.  22.]\n",
      "  [ 31.  23.  21.]\n",
      "  ...\n",
      "  [ 17.  17.  17.]\n",
      "  [ 18.  18.  20.]\n",
      "  [ 17.  17.  19.]]\n",
      "\n",
      " [[ 43.  45.  42.]\n",
      "  [ 47.  46.  42.]\n",
      "  [ 46.  43.  38.]\n",
      "  ...\n",
      "  [ 18.  18.  16.]\n",
      "  [ 21.  20.  18.]\n",
      "  [ 20.  19.  17.]]]\n",
      "----\n",
      "[[[[230. 231. 233.]\n",
      "   [231. 232. 234.]\n",
      "   [229. 233. 234.]\n",
      "   ...\n",
      "   [ 23.  34.  36.]\n",
      "   [ 23.  35.  33.]\n",
      "   [ 26.  38.  36.]]\n",
      "\n",
      "  [[234. 229. 233.]\n",
      "   [232. 230. 233.]\n",
      "   [232. 232. 234.]\n",
      "   ...\n",
      "   [ 27.  41.  44.]\n",
      "   [ 33.  43.  45.]\n",
      "   [ 34.  44.  46.]]\n",
      "\n",
      "  [[234. 229. 233.]\n",
      "   [232. 230. 233.]\n",
      "   [233. 231. 234.]\n",
      "   ...\n",
      "   [ 16.  44.  47.]\n",
      "   [ 25.  46.  49.]\n",
      "   [ 21.  42.  45.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 22.  21.  19.]\n",
      "   [ 24.  18.  18.]\n",
      "   [ 26.  18.  16.]\n",
      "   ...\n",
      "   [ 16.  16.  16.]\n",
      "   [ 18.  18.  20.]\n",
      "   [ 17.  17.  19.]]\n",
      "\n",
      "  [[ 28.  27.  25.]\n",
      "   [ 30.  25.  22.]\n",
      "   [ 31.  23.  21.]\n",
      "   ...\n",
      "   [ 17.  17.  17.]\n",
      "   [ 18.  18.  20.]\n",
      "   [ 17.  17.  19.]]\n",
      "\n",
      "  [[ 43.  45.  42.]\n",
      "   [ 47.  46.  42.]\n",
      "   [ 46.  43.  38.]\n",
      "   ...\n",
      "   [ 18.  18.  16.]\n",
      "   [ 21.  20.  18.]\n",
      "   [ 20.  19.  17.]]]]\n",
      "----\n",
      "[[[[ 129.061     114.221     106.32    ]\n",
      "   [ 130.061     115.221     107.32    ]\n",
      "   [ 130.061     116.221     105.32    ]\n",
      "   ...\n",
      "   [ -67.939     -82.779    -100.68    ]\n",
      "   [ -70.939     -81.779    -100.68    ]\n",
      "   [ -67.939     -78.779     -97.68    ]]\n",
      "\n",
      "  [[ 129.061     112.221     110.32    ]\n",
      "   [ 129.061     113.221     108.32    ]\n",
      "   [ 130.061     115.221     108.32    ]\n",
      "   ...\n",
      "   [ -59.939003  -75.779     -96.68    ]\n",
      "   [ -58.939003  -73.779     -90.68    ]\n",
      "   [ -57.939003  -72.779     -89.68    ]]\n",
      "\n",
      "  [[ 129.061     112.221     110.32    ]\n",
      "   [ 129.061     113.221     108.32    ]\n",
      "   [ 130.061     114.221     109.32    ]\n",
      "   ...\n",
      "   [ -56.939003  -72.779    -107.68    ]\n",
      "   [ -54.939003  -70.779     -98.68    ]\n",
      "   [ -58.939003  -74.779    -102.68    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ -84.939     -95.779    -101.68    ]\n",
      "   [ -85.939     -98.779     -99.68    ]\n",
      "   [ -87.939     -98.779     -97.68    ]\n",
      "   ...\n",
      "   [ -87.939    -100.779    -107.68    ]\n",
      "   [ -83.939     -98.779    -105.68    ]\n",
      "   [ -84.939     -99.779    -106.68    ]]\n",
      "\n",
      "  [[ -78.939     -89.779     -95.68    ]\n",
      "   [ -81.939     -91.779     -93.68    ]\n",
      "   [ -82.939     -93.779     -92.68    ]\n",
      "   ...\n",
      "   [ -86.939     -99.779    -106.68    ]\n",
      "   [ -83.939     -98.779    -105.68    ]\n",
      "   [ -84.939     -99.779    -106.68    ]]\n",
      "\n",
      "  [[ -61.939003  -71.779     -80.68    ]\n",
      "   [ -61.939003  -70.779     -76.68    ]\n",
      "   [ -65.939     -73.779     -77.68    ]\n",
      "   ...\n",
      "   [ -87.939     -98.779    -105.68    ]\n",
      "   [ -85.939     -96.779    -102.68    ]\n",
      "   [ -86.939     -97.779    -103.68    ]]]]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Default input size for VGG16\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "no_of_channels_in_rgb = 3\n",
    "image_size = (224, 224)\n",
    "# load model without classifier layers\n",
    "base_model = VGG19(weights='imagenet',include_top=False, input_shape=(img_width, img_height, no_of_channels_in_rgb))\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(base_model.layers[-1].output)\n",
    "print(flat1)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "output = Dense(20, activation='softmax')(class1)\n",
    "# define new model\n",
    "pre_trained_model = Model(inputs=base_model.inputs, outputs=flat1)\n",
    "# summarize\n",
    "pre_trained_model.summary()\n",
    "\n",
    "#train_labels = [['person',1],['aeroplane',2],['tvmonitor',3],['train',4],['boat',5],['dog',6],['chair',7],['bird',8],['bicycle',9],['bottle',10],['diningtable',11],['sheep','horse',12],['sofa',13],['cat',14]]\n",
    "#train_labels = ['person','aeroplane','tvmonitor','train','boat','dog','chair','bird','bicycle','bottle','diningtable','sheep','horse','sofa','cat']\n",
    "#train_labels = ['person','aeroplane','tvmonitor','train','boat','dog','chair','bird','bicycle','bottle']\n",
    "\n",
    "# encode the labels\n",
    "print(\"encoding labels.\")\n",
    "le = LabelEncoder()\n",
    "#le_labels = le.fit_transform(train_labels)\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, file in enumerate(os.listdir(\"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/JPEGImages1\")):\n",
    "  name = file.split(\".\")\n",
    "  image_path = \"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/JPEGImages1/\" + name[0]+\".jpg\"\n",
    "  annotation_path = \"/Users/utkarsh/Desktop/study/iitj/sem2/ml2/assignment/VOCdevkit/VOC2012/Annotations/\" + name[0]+\".xml\"\n",
    "  #print(file)\n",
    "  #print(annotation_path)\n",
    "  #print('image_path')\n",
    "  #print(image_path)\n",
    "  img = image.load_img(image_path, target_size=image_size)\n",
    "  # Converts a PIL Image to 3D Numy Array\n",
    "  # Adding the fouth dimension, for number of images\n",
    "  x = image.img_to_array(img)\n",
    "  print(x)\n",
    "  print(\"----\")\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  print(x)\n",
    "  print(\"----\")\n",
    "  x = preprocess_input(x)\n",
    "  print(x)\n",
    "  print(\"----\")\n",
    "  feature = pre_trained_model.predict(x)\n",
    "  flat = feature.flatten()\n",
    "  features.append(flat)\n",
    "  tree = ElementTree.parse(annotation_path)\n",
    "  #get the root of the document\n",
    "  root = tree.getroot()\n",
    "  objects=root.find('.//object')\n",
    "  label=objects.find('name').text\n",
    "  labels.append(label)\n",
    "  count += 1\n",
    "  break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166d200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "930e46df0d1b93ecf8fe51f04b6e478dce688000f1283825e61bc5e483dc45d1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3613jvsc74a57bd0930e46df0d1b93ecf8fe51f04b6e478dce688000f1283825e61bc5e483dc45d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
