{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5: Classification with Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0\n",
    "\n",
    "\n",
    "savePath = 'lecture5_output/'\n",
    "if not os.path.isdir(savePath):\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading saved features from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved features\n",
    "with open(\"trainFeats.pckl\", \"rb\") as f:\n",
    "    trainFeats = pickle.load(f)\n",
    "with open(\"trainLabel.pckl\", \"rb\") as f:\n",
    "    trainLabel = pickle.load(f)\n",
    "    \n",
    "with open(\"testFeats.pckl\", \"rb\") as f:\n",
    "    testFeats = pickle.load(f)\n",
    "with open(\"testLabel.pckl\", \"rb\") as f:\n",
    "    testLabel = pickle.load(f)\n",
    "    \n",
    "print('Finished loading saved feature matrices from the disk!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the perceptron\n",
    "class perceptron(nn.Module):\n",
    "    def __init__(self,n_channels): #n_channels => length of feature vector\n",
    "        super(perceptron, self).__init__()\n",
    "        self.L = nn.Linear(n_channels,10) #Mapping from input to output\n",
    "    def forward(self,x): #x => Input\n",
    "        x = self.L(x) #Feed-forward  \n",
    "        x = F.softmax(x,dim=1) #Softmax non-linearity, dim=1 corresponds to labels\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 1-hot label vectors\n",
    "trainLabel2 = np.zeros((50000,10))\n",
    "testLabel2 = np.zeros((10000,10))\n",
    "for d1 in range(trainLabel.shape[0]):\n",
    "    trainLabel2[d1,trainLabel[d1]] = 1\n",
    "for d2 in range(testLabel.shape[0]):\n",
    "    testLabel2[d2,testLabel[d2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "    pinMem = True\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\"\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch dataset from the feature matices\n",
    "trainDataset = TensorDataset(torch.from_numpy(trainFeats), torch.from_numpy(trainLabel2))\n",
    "testDataset = TensorDataset(torch.from_numpy(testFeats), torch.from_numpy(testLabel2))\n",
    "# Creating dataloader\n",
    "trainLoader = DataLoader(trainDataset, batch_size=64, shuffle=True,num_workers=4, pin_memory=pinMem)\n",
    "testLoader = DataLoader(testDataset, batch_size=64, shuffle=False,num_workers=4, pin_memory=pinMem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function for training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definining the training routine\n",
    "def train_model(model,criterion,num_epochs,learning_rate):\n",
    "        start = time.time()\n",
    "        train_loss = [] #List for saving the loss per epoch    \n",
    "        train_acc = [] #List for saving the accuracy per epoch  \n",
    "        tempLabels = [] #List for saving shuffled labels as fed into the network\n",
    "        for epoch in range(num_epochs):\n",
    "            epochStartTime = time.time()\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "            running_loss = 0.0           \n",
    "            # Loading data in batches\n",
    "            batch = 0\n",
    "            for data in tqdm.tqdm_notebook(trainLoader):\n",
    "                inputs,labels = data\n",
    "                \n",
    "                inputs, labels = inputs.float().to(device),labels.float().to(device)\n",
    "                \n",
    "                # Initializing model gradients to zero\n",
    "                model.zero_grad() \n",
    "                # Data feed-forward through the network\n",
    "                outputs = model(inputs)\n",
    "                # Predicted class is the one with maximum probability\n",
    "                _, preds = outputs.data.max(1)                 \n",
    "                # Finding the MSE\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Accumulating the loss for each batch\n",
    "                running_loss += loss.item()          \n",
    "    \n",
    "                # Backpropaging the error\n",
    "                if batch == 0:\n",
    "                    totalLoss = loss\n",
    "                    totalPreds = preds                    \n",
    "                    tempLabels = labels.data.cpu()\n",
    "                    batch += 1                    \n",
    "                else:\n",
    "                    totalLoss += loss \n",
    "                    totalPreds = torch.cat((totalPreds,preds),0)                 \n",
    "                    tempLabels = torch.cat((tempLabels,labels.data.cpu()),0)\n",
    "                    batch += 1\n",
    "                    \n",
    "            totalLoss = totalLoss/batch\n",
    "            totalLoss.backward()\n",
    "            \n",
    "            # Updating the model parameters\n",
    "            for f in model.parameters():\n",
    "                f.data.sub_(f.grad.data * learning_rate) \n",
    "                                    \n",
    "            epoch_loss = running_loss/50000  #Total loss for one epoch\n",
    "            train_loss.append(epoch_loss) #Saving the loss over epochs for plotting the graph\n",
    "            \n",
    "            # Accuracy per epoch\n",
    "            tempLabels = tempLabels.numpy()\n",
    "            _,totalLabels = np.where(tempLabels==1)                        \n",
    "            epoch_acc = np.sum(np.equal(totalPreds.cpu().numpy(),np.array(totalLabels)))/50000.0      \n",
    "            train_acc.append(epoch_acc*100) #Saving the accuracy over epochs for plotting the graph\n",
    "            \n",
    "            epochTimeEnd = time.time()-epochStartTime\n",
    "            print('Average epoch loss: {:.6f}'.format(epoch_loss))\n",
    "            print('Average epoch accuracy: {:.4f} %'.format(epoch_acc*100))\n",
    "            print('-' * 25)\n",
    "            # Plotting Loss vs Epochs\n",
    "            fig1 = plt.figure(1)        \n",
    "            plt.plot(range(epoch+1),train_loss,'r--',label='train')      \n",
    "            if epoch == 0:\n",
    "                plt.legend(loc='upper right')\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.title('Plot of training loss vs epochs')\n",
    "            fig1.savefig(savePath+'lossPlot.png')\n",
    "             # Plotting Accuracy vs Epochs\n",
    "            fig2 = plt.figure(2)        \n",
    "            plt.plot(range(epoch+1),train_acc,'g--',label='train')  \n",
    "            if epoch == 0:\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.xlabel('Epochs')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.title('Plot of training accuracy vs epochs')\n",
    "            fig2.savefig(savePath+'accPlot.png')\n",
    "\n",
    "        time_elapsed = time.time() - start\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featLength = 2+5+2\n",
    "# Initilaizing the model\n",
    "model = perceptron(featLength).to(device)\n",
    "criterion = nn.MSELoss() \n",
    "model = train_model(model,criterion,num_epochs=100,learning_rate=1) # Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation of trained perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding testing accuracy\n",
    "test_running_corr = 0\n",
    "# Loading data in batches\n",
    "batches = 0\n",
    "testLabels = []\n",
    "\n",
    "model.eval() # Testing the model in evaluation mode\n",
    "\n",
    "for tsData in tqdm.tqdm_notebook(testLoader):\n",
    "    inputs,labels = tsData\n",
    "    \n",
    "    inputs, labels = inputs.float().to(device),labels.float()      \n",
    "    \n",
    "    with torch.no_grad(): # No back-propagation during testing; gradient computation is not required\n",
    "        \n",
    "        # Feedforward train data batch through model\n",
    "        output = model(inputs) \n",
    "        # Predicted class is the one with maximum probability\n",
    "        _,preds = output.data.max(1)    \n",
    "        if batches==0:\n",
    "            totalPreds = preds\n",
    "            testLabels = torch.argmax(labels,dim=1) # Converting 1-hot vector labels to integer labels\n",
    "            batches = 1\n",
    "        else:\n",
    "            totalPreds = torch.cat((totalPreds,preds),0)\n",
    "            testLabels = torch.cat((testLabels,torch.argmax(labels,dim=1)),0) \n",
    "\n",
    "# Finding total number of correct predictions\n",
    "ts_corr = np.sum(np.equal(totalPreds.cpu().numpy(),testLabels.numpy()))\n",
    "# Calculating accuracy\n",
    "ts_acc = ts_corr/testLabels.shape[0]\n",
    "print('Accuracy on test set = '+str(ts_acc*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
