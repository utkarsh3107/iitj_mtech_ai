{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 54: Adversarial Autoencoder for Synthetic Sample Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset \n",
    "dataset = dsets.MNIST(root='./MNIST', train=True, transform=transforms.ToTensor(),  download=True)\n",
    "testset = dsets.MNIST(root='./MNIST', train=False, transform=transforms.ToTensor(),  download=True)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False # Uncomment in case of GPU memory error\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Q_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3gauss = nn.Linear(N, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        xgauss = self.lin3gauss(x)\n",
    "        return xgauss\n",
    "\n",
    "# Decoder\n",
    "class P_net(nn.Module):  \n",
    "    def __init__(self,X_dim,N,z_dim):\n",
    "        super(P_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Discriminator\n",
    "class D_net_gauss(nn.Module):  \n",
    "    def __init__(self,N,z_dim):\n",
    "        super(D_net_gauss, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        return torch.sigmoid(self.lin3(x))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_red_dims = 2\n",
    "Q = Q_net(784,1000,z_red_dims).to(device)\n",
    "P = P_net(784,1000,z_red_dims).to(device)\n",
    "D_gauss = D_net_gauss(500,z_red_dims).to(device)\n",
    "\n",
    "\n",
    "# Set learning rates\n",
    "gen_lr = 0.0001\n",
    "reg_lr = 0.00005\n",
    "\n",
    "#encode/decode optimizers\n",
    "optim_P = optim.Adam(P.parameters(), lr=gen_lr)\n",
    "optim_Q_enc = optim.Adam(Q.parameters(), lr=gen_lr)\n",
    "#regularizing optimizers\n",
    "optim_Q_gen = optim.Adam(Q.parameters(), lr=reg_lr)\n",
    "optim_D = optim.Adam(D_gauss.parameters(), lr=reg_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 100\n",
    "\n",
    "test_noise = torch.Tensor(num_test_samples,z_red_dims)\n",
    "p = [-1,1,-1,1]\n",
    "q = [-1,1,1,-1]\n",
    "for loop in range(4):\n",
    "    \n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            test_noise[25*loop+i*5+j] = torch.Tensor([(i+1)*0.4*p[loop], (j+1)*0.4*q[loop]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 5000\n",
    "\n",
    "# Start training\n",
    "for step in range(total_step):\n",
    "\n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch the images and labels and convert them to variables\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "\n",
    "    #reconstruction loss\n",
    "    P.zero_grad()\n",
    "    Q.zero_grad()\n",
    "    D_gauss.zero_grad()\n",
    "\n",
    "    z_sample = Q(images)   #encode to z\n",
    "    X_sample = P(z_sample) #decode to X reconstruction\n",
    "    recon_loss = F.binary_cross_entropy(X_sample,images)\n",
    "\n",
    "    recon_loss.backward()\n",
    "    optim_P.step()\n",
    "    optim_Q_enc.step()\n",
    "\n",
    "    # Discriminator\n",
    "    ## true prior is random normal (randn)\n",
    "    ## this is constraining the Z-projection to be normal!\n",
    "    Q.eval()    \n",
    "    z_real_gauss = torch.randn(images.size()[0], z_red_dims).to(device)\n",
    "    D_real_gauss = D_gauss(z_real_gauss)\n",
    "\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "\n",
    "    D_loss = -torch.mean(torch.log(D_real_gauss) + torch.log(1 - D_fake_gauss))\n",
    "\n",
    "    D_loss.backward()\n",
    "    optim_D.step()\n",
    "\n",
    "    # Generator\n",
    "    Q.train()\n",
    "    z_fake_gauss = Q(images)\n",
    "    D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "    \n",
    "    G_loss = -torch.mean(torch.log(D_fake_gauss))\n",
    "\n",
    "    G_loss.backward()\n",
    "    optim_Q_gen.step()   \n",
    "    \n",
    "    P.eval()\n",
    "    test_images = P(test_noise.to(device))\n",
    "    P.train()\n",
    "    if use_gpu:\n",
    "            test_images = test_images.cpu().detach()\n",
    "    for k in range(num_test_samples):\n",
    "        i = k//10\n",
    "        j = k%10\n",
    "        ax[i,j].cla()        \n",
    "        ax[i,j].imshow(test_images[k,:].numpy().reshape(28, 28), cmap='Greys')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
