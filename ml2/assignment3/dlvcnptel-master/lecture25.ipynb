{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 25: SGD and ADAM Learning Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim #Structural similarity index\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 100\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = NeuralNet()\n",
    "net2 = NeuralNet()\n",
    "net3 = NeuralNet()\n",
    "\n",
    "net1 = net1.to(device) # Network to be trained using SGD\n",
    "net2 = net2.to(device) # Network to be trained using SGD with momentum\n",
    "net3 = net3.to(device) # Network to be trained using Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with different Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model,optimizer,criterion,datainput,label):\n",
    "    model.train() # For training\n",
    "    optimizer.zero_grad()\n",
    "    output = model(datainput)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=1e-4) # SGD\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=1e-4, momentum=0.9) # SGD with momentum\n",
    "optimizer3 = optim.Adam(net3.parameters(), lr=1e-4) # Adam\n",
    "\n",
    "Plotacc1 = []\n",
    "Plotacc2 = []\n",
    "Plotacc3 = []\n",
    "\n",
    "plotLoss1 = []\n",
    "plotLoss2 = []\n",
    "plotLoss3 = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    correct3 = 0\n",
    "    runningLoss1 = 0\n",
    "    runningLoss2 = 0\n",
    "    runningLoss3 = 0\n",
    "    total = 0    \n",
    "    \n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.view(-1, 28*28).to(device), labels.to(device)         \n",
    "        trainLoss1 = Train(net1,optimizer1,criterion,inputs,labels)\n",
    "        trainLoss2 = Train(net2,optimizer2,criterion,inputs,labels)\n",
    "        trainLoss3 = Train(net3,optimizer3,criterion,inputs,labels)\n",
    "\n",
    "        runningLoss1 += trainLoss1\n",
    "        runningLoss2 += trainLoss2\n",
    "        runningLoss3 += trainLoss3\n",
    "   \n",
    "    runningLoss1 = runningLoss1/(i+1)\n",
    "    runningLoss2 = runningLoss2/(i+1)\n",
    "    runningLoss3 = runningLoss3/(i+1)\n",
    "          \n",
    "   \n",
    "    plotLoss1.append(runningLoss1)\n",
    "    plotLoss2.append(runningLoss2)\n",
    "    plotLoss3.append(runningLoss3)\n",
    "    \n",
    "    net1.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
    "    net2.eval()\n",
    "    net3.eval()\n",
    "    with torch.no_grad(): # Gradient computation is not involved in inference\n",
    "    \n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.view(-1, 28*28).to(device), labels.to(device)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            outputs = net1(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct1 += (predicted == labels).sum()\n",
    "\n",
    "            outputs = net2(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct2 += (predicted == labels).sum()\n",
    "\n",
    "            outputs = net3(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct3 += (predicted == labels).sum()\n",
    "\n",
    "    Plotacc1.append(float(correct1)*100/float(total))\n",
    "    Plotacc2.append(float(correct2)*100/float(total))\n",
    "    Plotacc3.append(float(correct3)*100/float(total))\n",
    "    \n",
    "    print('At Epoch '+str(epoch+1))\n",
    "    print('SGD: Loss = {:.6f} , Acc = {:.4f}'.format(runningLoss1,float(correct1)*100/float(total)))\n",
    "    print('SGD with momentum: Loss = {:.6f} , Acc = {:.4f}'.format(runningLoss2,float(correct2)*100/float(total)))\n",
    "    print('Adam: Loss = {:.6f} , Acc = {:.4f}'.format(runningLoss3,float(correct3)*100/float(total)))\n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),plotLoss1,'r-',label='SGD')\n",
    "plt.plot(range(epoch+1),plotLoss2,'g-',label='SGD with momentum')   \n",
    "plt.plot(range(epoch+1),plotLoss3,'b-',label='Adam')  \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')  \n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),Plotacc1,'r-',label='SGD')\n",
    "plt.plot(range(epoch+1),Plotacc2,'g-',label='SGD with momentum')\n",
    "plt.plot(range(epoch+1),Plotacc3,'b-',label='Adam')    \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing Accuracy')  \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
