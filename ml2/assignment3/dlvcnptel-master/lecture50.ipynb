{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 50: Semantic Segmentation\n",
    "\n",
    "## Dataset used: [DRIVE](https://www.isi.uu.nl/Research/Databases/DRIVE/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'DRIVE/training/'\n",
    "testPath = 'DRIVE/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying sample image, groundtruth and mask from the dataset\n",
    "sampleImg = np.array(Image.open(trainPath+'images/21_training.tif'))\n",
    "sampleGT = np.array(Image.open(trainPath+'1st_manual/21_manual1.gif'))\n",
    "sampleMask = np.array(Image.open(trainPath+'mask/21_training_mask.gif'))\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(sampleImg)\n",
    "plt.title('Image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(sampleGT,cmap='gray')\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(133)\n",
    "plt.imshow(sampleMask,cmap='gray')\n",
    "plt.title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRIVE dataset has 20 images for training and 20 for testing\n",
    "TrainImages = torch.FloatTensor(600,3,224,224) # 20 images x 30 patches\n",
    "TrainLabels = torch.FloatTensor(600,224,224)\n",
    "TestImages = torch.FloatTensor(20,3,224,224)\n",
    "TestLabels = torch.FloatTensor(20,224,224)\n",
    "\n",
    "# Obtain list containing name of all files in the directoy\n",
    "trainImgList = os.listdir(trainPath+'images')\n",
    "testImgList = os.listdir(testPath+'images')\n",
    "\n",
    "# Preparing train data tensors\n",
    "img_no = 0\n",
    "for file in trainImgList:\n",
    "    imgNum = file.split('_')[0] # Image number from the filename\n",
    "    im = Image.open(trainPath+'images/'+ file)\n",
    "    seg = Image.open(trainPath+'1st_manual/'+str(imgNum)+'_manual1.gif')\n",
    "    mask = Image.open(trainPath+'mask/'+str(imgNum)+'_training_mask.gif')\n",
    "    im = np.array(im)\n",
    "    seg = np.array(seg)/255\n",
    "    mask = (np.array(mask)/255-seg)\n",
    "    idx = np.where(mask==1)\n",
    "    # Note: In the GT (seg), 0--> BG, 1--> Vessels, 2--> Tissue(mask)\n",
    "    seg[idx] = 2\n",
    "    \n",
    "    # Augmenting training data by taking 30 patches, each of size 224x224, from the original image\n",
    "    randIdx1 = np.random.randint(0,im.shape[0]-224,30) \n",
    "    randIdx2 = np.random.randint(0,im.shape[1]-224,30)\n",
    "    for p in range(30):\n",
    "        patch = im[randIdx1[p]:randIdx1[p]+224,randIdx2[p]:randIdx2[p]+224,:]/255\n",
    "        seg_patch = seg[randIdx1[p]:randIdx1[p]+224,randIdx2[p]:randIdx2[p]+224]\n",
    "        TrainImages[img_no] = torch.from_numpy(patch).transpose(0,2).unsqueeze(0)\n",
    "        TrainLabels[img_no] = torch.from_numpy(seg_patch).transpose(0,1).unsqueeze(0)\n",
    "        img_no += 1\n",
    "\n",
    "# Preparing test data tensors\n",
    "img_no = 0\n",
    "for file in testImgList:\n",
    "    imgNum = file.split('_')[0] # Image number from the filename\n",
    "    im = Image.open(testPath+'images/'+ file)\n",
    "    seg = Image.open(testPath+'1st_manual/'+str(imgNum)+'_manual1.gif')\n",
    "    mask = Image.open(testPath+'mask/'+str(imgNum)+'_test_mask.gif')\n",
    "    # Resizing the images to 224x224\n",
    "    im = np.array(im.resize((224,224)))/255\n",
    "    seg = np.array(seg.resize((224,224)))/255\n",
    "    mask = (np.array(mask.resize((224,224)))-seg)/255\n",
    "    idx = np.where(mask==1)\n",
    "    # Note: In the GT (seg), 0--> BG, 1--> Vessels, 2--> Tissue(mask)\n",
    "    seg[idx] = 2\n",
    "    TestImages[img_no] = torch.from_numpy(im).transpose(0,2).unsqueeze(0)\n",
    "    TestLabels[img_no] = torch.from_numpy(seg).transpose(0,1).unsqueeze(0)\n",
    "    img_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainImages.size())\n",
    "print(TrainLabels.size())\n",
    "print(TestImages.size())\n",
    "print(TestLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch dataset\n",
    "trainDataset = TensorDataset(TrainImages, TrainLabels)\n",
    "testDataset = TensorDataset(TestImages, TestLabels)\n",
    "# Creating dataloader\n",
    "BatchSize = 10\n",
    "trainLoader = DataLoader(trainDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)\n",
    "testLoader = DataLoader(testDataset, batch_size=BatchSize, shuffle=False,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False # Uncomment in case of GPU memory error\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()        \n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1c = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.mup1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.conv1d = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1c(x))\n",
    "        x, idx1 = self.mp1(x)    \n",
    "        x = self.mup1(x, idx1)\n",
    "        x = self.conv1d(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-Likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 15\n",
    "trainLoss = []\n",
    "testLoss = []\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0   \n",
    "    net.train() # For training\n",
    "    for data in tqdm.tqdm_notebook(trainLoader):\n",
    "        inputs,labels = data\n",
    "        inputs, labels = inputs.to(device), labels.long().to(device) \n",
    "        \n",
    "        # Feed-forward input data through the network\n",
    "        outputs = net(inputs)\n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs,dim=1), labels)      \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()                  \n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.item()\n",
    "    avgTrainLoss = runningLoss/(600.0 /BatchSize)   \n",
    "    trainLoss.append(avgTrainLoss)\n",
    "  \n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.eval() # For testing\n",
    "    test_runningLoss = 0    \n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            inputs,labels = data\n",
    "            inputs, labels = inputs.to(device), labels.long().to(device)         \n",
    "            outputs = net(inputs)       \n",
    "             # Compute loss/error\n",
    "            loss = criterion(F.log_softmax(outputs,dim=1), labels)      \n",
    "            # Accumulate loss per batch\n",
    "            test_runningLoss += loss.item() \n",
    "        \n",
    "    avgTestLoss = test_runningLoss/(20.0/BatchSize)  \n",
    "    testLoss.append(avgTestLoss)\n",
    "        \n",
    "    # Plotting Loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r--',label='train')        \n",
    "    plt.plot(range(epoch+1),testLoss,'g--',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "      \n",
    "    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f}; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,epochEnd//60,epochEnd%60))\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Testing Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTestLoss,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing segmentation on one of the test images\n",
    "randIdx = np.random.randint(20)\n",
    "testImg = TestImages[randIdx]\n",
    "testLab = TestLabels[randIdx].numpy()\n",
    "\n",
    "# Feed-forward \n",
    "segImg = net(testImg.unsqueeze(0).to(device))\n",
    "# Applying softmax to get class probabilities\n",
    "segImg_np = F.softmax(segImg,dim=1).data.squeeze(0)\n",
    "if use_gpu:\n",
    "    segImg_np = segImg_np.cpu()\n",
    "segImg_np = segImg_np.numpy()\n",
    "\n",
    "# Displaying segmented output and ground truth\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(231)\n",
    "plt.imshow(segImg_np[0,:,:],cmap='gray')\n",
    "plt.title('Channel 1')\n",
    "plt.subplot(232)\n",
    "plt.imshow(segImg_np[1,:,:],cmap='gray')\n",
    "plt.title('Channel 2')\n",
    "plt.subplot(233)\n",
    "plt.imshow(segImg_np[2,:,:],cmap='gray')\n",
    "plt.title('Channel 3')\n",
    "\n",
    "\n",
    "bg = testLab==0\n",
    "vessel = testLab==1\n",
    "tissue = testLab==2\n",
    "plt.subplot(234)\n",
    "plt.imshow(bg,cmap='gray')\n",
    "plt.title('Background')\n",
    "plt.subplot(235)\n",
    "plt.imshow(vessel,cmap='gray')\n",
    "plt.title('Vessel')\n",
    "plt.subplot(236)\n",
    "plt.imshow(tissue,cmap='gray')\n",
    "plt.title('Tissue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
