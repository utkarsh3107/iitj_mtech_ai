{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 60: Activity recognition using CNN-LSTM\n",
    "## 60a: Train CNN for activity classification\n",
    "\n",
    "#### Note:\n",
    "      1. Run lecture59_preProc1.ipynb before running executing this notebook\n",
    "      2. Files lecture60a.ipynb, lecture60b.ipynb, lecture60c.ipynb are part of the same tutorial and are to be exeuted sequentially  \n",
    "#### Dataset: [UCF101](https://www.crcv.ucf.edu/research/data-sets/ucf101/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms,datasets, models\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# use_gpu = False # Uncomment in case of GPU memory error\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "    pinMem = True\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\"\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from folder using ImageFolder\n",
    "trainDir = 'train_5class'\n",
    "valDir = 'test_5class'\n",
    "apply_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "BatchSize = 128\n",
    "# Training dataloader\n",
    "train_dataset = datasets.ImageFolder(trainDir,transform=apply_transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=pinMem)\n",
    "\n",
    "# Test dataloader\n",
    "test_dataset = datasets.ImageFolder(valDir,transform=apply_transform)\n",
    "testLoader = torch.utils.data.DataLoader(test_dataset, batch_size=BatchSize, shuffle=False,num_workers=4, pin_memory=pinMem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of train and test datasets\n",
    "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
    "print('No. of samples in test set: '+str(len(testLoader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counting number of trainable parameters\n",
    "totalParams = 0\n",
    "for name,params in net.named_parameters():\n",
    "    print(name,'-->',params.size())\n",
    "    totalParams += np.sum(np.prod(params.size()))\n",
    "print('Total number of parameters: '+str(totalParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the last fully-connected layer for 5 classes\n",
    "net.fc = nn.Linear(512,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.fc.parameters(), lr=1e-4) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "trainLoss = []\n",
    "trainAcc = []\n",
    "testLoss = []\n",
    "testAcc = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0   \n",
    "    avgTotalLoss = 0.0\n",
    "    running_correct = 0   \n",
    "    \n",
    "    net.train() # For training \n",
    "    batchNum = 1\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels.data).sum()            \n",
    "       \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()             \n",
    "        \n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs,dim=1), labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.item() \n",
    "        batchNum += 1\n",
    "\n",
    "    avgTrainAcc = 100*float(running_correct)/float(len(trainLoader.dataset))\n",
    "    avgTrainLoss = runningLoss/(float(len(trainLoader.dataset))/BatchSize)  \n",
    "    trainAcc.append(avgTrainAcc)\n",
    "    trainLoss.append(avgTrainLoss)  \n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
    "    running_correct = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            inputs,labels = data\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)                \n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_correct += (predicted == labels.data).sum()\n",
    "        \n",
    "            loss = criterion(F.log_softmax(outputs,dim=1), labels)\n",
    "        \n",
    "            runningLoss += loss.item()   \n",
    "\n",
    "    avgTestLoss = runningLoss/(float(len(testLoader.dataset))/BatchSize)\n",
    "    avgTestAcc = 100*float(running_correct)/float(len(testLoader.dataset))\n",
    "    testAcc.append(avgTestAcc)  \n",
    "    testLoss.append(avgTestLoss)\n",
    "    \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r-',label='train')  \n",
    "    plt.plot(range(epoch+1),testLoss,'g-',label='test') \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epoch+1),trainAcc,'r-',label='train')    \n",
    "    plt.plot(range(epoch+1),testAcc,'g-',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')  \n",
    "          \n",
    "        \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f};  Training Loss: {:.6f} ; Training Acc: {:.3f}'\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,avgTrainAcc))\n",
    "    print('Iteration: {:.0f} /{:.0f};  Testing Loss: {:.6f} ; Testing Acc: {:.3f}'\\\n",
    "          .format(epoch + 1,iterations,avgTestLoss,avgTestAcc))\n",
    "   \n",
    "    print('Time consumed: {:.0f}m {:.0f}s'.format(epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet18Pre_fcOnly5class_ucf101_10adam_1e-4_b128.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
