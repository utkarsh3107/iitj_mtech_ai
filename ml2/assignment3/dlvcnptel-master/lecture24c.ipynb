{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24c: Gradient Descent Learning Rule\n",
    "### Updating parameters for every training sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "BatchSize = 100\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of training samples = '+str(len(trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 3\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "Plotacc = []\n",
    "trainLoss = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    start = time.time()\n",
    "    correct = 0  \n",
    "    runningLoss = 0    \n",
    "    total = 0\n",
    "    net.train() # For training\n",
    "    for i in range(len(trainset)): # i-->Sample number\n",
    "        # get the inputs\n",
    "        inputs = trainset[i][0]\n",
    "        labels = trainset[i][1]*torch.ones(1)       \n",
    "        inputs, labels = inputs.view(-1, 28*28).to(device), labels.long().to(device)        \n",
    "              \n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss                 \n",
    "   \n",
    "        # Updating parameters for every training smaple      \n",
    "        net.zero_grad()  # zeroes the gradient buffers of all parameters    \n",
    "        loss.backward()\n",
    "        for f in net.parameters():\n",
    "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights) \n",
    "        runningLoss += loss.item()\n",
    "    \n",
    "    trainLoss.append(runningLoss/(i+1))   \n",
    "    \n",
    "    net.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
    "    with torch.no_grad(): # Gradient computation is not involved in inference\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.view(-1, 28*28).to(device), labels.to(device)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum()        \n",
    "\n",
    "    Plotacc.append(float(correct)*100/float(total))\n",
    "    epochTimeEnd = time.time()-start\n",
    "    print('At Epoch {:.0f}: Loss = {:.6f} , Acc = {:.4f} %'.format(epoch+1,runningLoss/(i+1),float(correct)*100.0/float(total)))   \n",
    "    print('Epoch completed in {:.0f}m {:.0f}s'.format(epochTimeEnd // 60, epochTimeEnd % 60))\n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'r-',label='Cross Entropy Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')  \n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),Plotacc,'g-',label='Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing Accuracy')  \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
