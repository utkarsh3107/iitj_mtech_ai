{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 14: ALL-IDB Classification using Autoencoders\n",
    "\n",
    "### Dataset used:- [ALL-IDB:Acute Lymphoblastic Leukemia Image Database for Image Processing](https://homes.di.unimi.it/scotti/all/)\n",
    "Follow the instructions provided in the linked website to download the dataset. After downloading, extract the files to the current directory (same folder as your codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datapath = 'ALL_IDB2/img/'\n",
    "listing = os.listdir(Datapath) \n",
    "random.shuffle(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImages = torch.DoubleTensor(200,3072)\n",
    "TrainLabels = torch.LongTensor(200)\n",
    "TestImages = torch.DoubleTensor(60,3072)\n",
    "TestLabels = torch.LongTensor(60)\n",
    "\n",
    "img_no = 0\n",
    "for file in listing:\n",
    "    im=Image.open(Datapath + file)\n",
    "    im = im.resize((32,32))\n",
    "    im = np.array(im)\n",
    "    im = np.reshape(im, 32*32*3)\n",
    "    if img_no < 200:\n",
    "        TrainImages[img_no] = torch.from_numpy(im)\n",
    "        TrainLabels[img_no] = int(listing[img_no][6:7])\n",
    "    else:\n",
    "        TestImages[img_no - 200] = torch.from_numpy(im)\n",
    "        TestLabels[img_no - 200] = int(listing[img_no][6:7])\n",
    "    img_no = img_no + 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainImages.size())\n",
    "print(TrainLabels.size())\n",
    "print(TestImages.size())\n",
    "print(TestLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(32*32*3, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 32*32*3),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "net = net.double().to(device)\n",
    "        \n",
    "init_weights = copy.deepcopy(net.encoder[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Optimization Technique:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30\n",
    "BatchSize = 10\n",
    "for epoch in range(iterations):\n",
    "    runningLoss = 0\n",
    "    for i in range(int(TrainImages.size()[0]/BatchSize)):\n",
    "        inputs = torch.index_select(TrainImages,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).double()\n",
    "        inputs = inputs/255\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,runningLoss/\n",
    "                                                                (TrainImages.size()[0]/BatchSize)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = copy.deepcopy(net.encoder[0].weight.data)\n",
    "init_weights = (1 + init_weights)*127.5\n",
    "trained_weights = (1 + trained_weights)*127.5\n",
    "\n",
    "init_weights = init_weights.view(3,320,320).byte()\n",
    "trained_weights = trained_weights.view(3,320,320).byte()\n",
    "\n",
    "if device == 'cuda':\n",
    "    init_weights = init_weights.cpu()\n",
    "    trained_weights = trained_weights.cpu()    \n",
    "\n",
    "d_weights = init_weights - trained_weights \n",
    "\n",
    "fig = plt.figure()\n",
    "plot=fig.add_subplot(1,3,1)\n",
    "img = np.array(init_weights.numpy())[0]\n",
    "plot.set_title('Initial Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,2)\n",
    "img = np.array(trained_weights.numpy())[0]\n",
    "plot.set_title('Trained Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,3)\n",
    "img = np.array(d_weights.numpy())[0]\n",
    "plot.set_title('Weight update')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classifier = nn.Sequential(*list(net.children())[:-1])\n",
    "net = new_classifier\n",
    "net.add_module('classifier', nn.Sequential(nn.Linear(100, 2),nn.LogSoftmax(dim=1)))\n",
    "print(net)\n",
    "net = net.double().to(device)\n",
    "cll_weights = copy.deepcopy(net[0][0].weight.data)\n",
    "init_classifier_weights = copy.deepcopy(net.classifier[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Optimizer:\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30\n",
    "BatchSize = 10\n",
    "for epoch in range(iterations):\n",
    "    runningLoss = 0\n",
    "    for i in range(int(TrainImages.size()[0]/BatchSize)):\n",
    "        inputs = torch.index_select(TrainImages,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).double()\n",
    "        labels = torch.index_select(TrainLabels,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).long()\n",
    "        inputs = inputs/255\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "        \n",
    "    inputs = TestImages.double()/255\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if use_gpu:        \n",
    "        predicted = predicted.cpu()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total += TestLabels.size(0)\n",
    "    correct += (predicted == TestLabels).sum()\n",
    "    print('At Iteration: %d / %d  ;  Training Loss: %f ; Testing Acc: %f '%(epoch + 1,iterations,runningLoss/\n",
    "                                                                            (TrainImages.size()[0]/\n",
    "                                                                             BatchSize),(100 * correct/ float(total))))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cll_weights_ft = copy.deepcopy(net[0][0].weight.data)\n",
    "cll_weights = (1 + cll_weights)*127.5\n",
    "cll_weights_ft = (1 + cll_weights_ft)*127.5\n",
    "\n",
    "cll_weights = cll_weights.view(3,320,320).byte()\n",
    "cll_weights_ft = cll_weights_ft.view(3,320,320).byte()\n",
    "if use_gpu:\n",
    "    cll_weights = cll_weights.cpu()\n",
    "    cll_weights_ft = cll_weights_ft.cpu()\n",
    "\n",
    "d_weights = cll_weights - cll_weights_ft\n",
    "\n",
    "fig = plt.figure()\n",
    "plot=fig.add_subplot(1,3,1)\n",
    "img = np.array(cll_weights.numpy())[0]\n",
    "plot.set_title('Encoder Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,2)\n",
    "img = np.array(cll_weights_ft.numpy())[0]\n",
    "plot.set_title('Finetuned Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,3)\n",
    "img = np.array(d_weights.numpy())[0]\n",
    "plot.set_title('Weight update')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Weights Visualization:\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier_weights = copy.deepcopy(net.classifier[0].weight.data)\n",
    "init_classifier_weights = (1 + init_classifier_weights)*255\n",
    "trained_classifier_weights = (1 + trained_classifier_weights)*255\n",
    "\n",
    "init_classifier_weights = init_classifier_weights.view(-1,20,10).byte()\n",
    "trained_classifier_weights = trained_classifier_weights.view(-1,20,10).byte()\n",
    "if use_gpu:\n",
    "    init_classifier_weights = init_classifier_weights.cpu()\n",
    "    trained_classifier_weights = trained_classifier_weights.cpu()\n",
    "\n",
    "d_weights = init_classifier_weights - trained_classifier_weights\n",
    "\n",
    "fig = plt.figure()\n",
    "plot=fig.add_subplot(1,3,1)\n",
    "img = np.array(init_classifier_weights.numpy())[0]\n",
    "plot.set_title('Initial Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,2)\n",
    "img = np.array(trained_classifier_weights.numpy())[0]\n",
    "plot.set_title('Trained Weights')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "plot=fig.add_subplot(1,3,3)\n",
    "img = np.array(d_weights.numpy())[0]\n",
    "plot.set_title('Weight update')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
