{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24a: Gradient Descent Learning Rule\n",
    "### Updating parameters once every epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(torch.__version__) # This code has been updated for PyTorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 100\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "Plotacc = []\n",
    "trainLoss = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    start = time.time()\n",
    "    correct = 0  \n",
    "    runningLoss = 0    \n",
    "    total = 0\n",
    "    net.train() # For training\n",
    "    for i,data in enumerate(trainloader): # i -> batch number\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.view(-1, 28*28).to(device), labels.to(device)         \n",
    "              \n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss   \n",
    "        if i == 0: #First batch              \n",
    "            totalLoss = loss                          \n",
    "        else:\n",
    "            totalLoss += loss               \n",
    "   \n",
    "    totalLoss = totalLoss/(i+1) \n",
    "    # updating parameters once in every epoch      \n",
    "    net.zero_grad()  # zeroes the gradient buffers of all parameters    \n",
    "    totalLoss.backward()\n",
    "    for f in net.parameters():\n",
    "        f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)      \n",
    "    \n",
    "    trainLoss.append(totalLoss.item())   \n",
    "    \n",
    "    net.eval() # For testing [Affects batch-norm and dropout layers (if any)]\n",
    "    with torch.no_grad(): # Gradient computation is not involved in inference\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.view(-1, 28*28).to(device), labels.to(device)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum()      \n",
    "\n",
    "    Plotacc.append(float(correct)*100/float(total))\n",
    "    epochTimeEnd = time.time()-start\n",
    "    print('At Epoch {:.0f}: Loss = {:.6f} , Acc = {:.4f}%'.format(epoch+1,totalLoss.item(),float(correct)*100/float(total)))   \n",
    "    print('Epoch completed in {:.0f}m {:.0f}s'.format(epochTimeEnd // 60, epochTimeEnd % 60))\n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'r-',label='Cross Entropy Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')  \n",
    "    \n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),Plotacc,'g-',label='Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing Accuracy')  \n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
